{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",\n",
    "    message=\"Values in x were outside bounds during a minimize step, clipping\",\n",
    "    category=RuntimeWarning, module=\"scipy.optimize._slsqp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.stats import beta as beta_rv, t as t_rv\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import betaln\n",
    "from arch import arch_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "# Innovations, simulation, Beta moments\n",
    "\n",
    "def standardized_beta_sample(a, b, size):\n",
    "    \"\"\"Draw Beta(a,b), standardize to mean 0, var 1.\"\"\"\n",
    "    raw = beta_rv.rvs(a, b, size=size)\n",
    "    mu = a / (a + b)\n",
    "    var = (a * b) / ((a + b) ** 2 * (a + b + 1))\n",
    "    return (raw - mu) / np.sqrt(var)\n",
    "\n",
    "def standardized_t_sample(df, size):\n",
    "    \"\"\"Draw t(df), standardize to mean 0, var 1 (df>2).\"\"\"\n",
    "    raw = t_rv.rvs(df, size=size)\n",
    "    return raw / np.sqrt(df / (df - 2)) if df > 2 else raw\n",
    "\n",
    "def simulate_garch(omega, alpha, beta_, eps):\n",
    "    \"\"\"\n",
    "    Simulate GARCH(1,1): y_t = sigma_t * eps_t, \n",
    "    sigma_t^2 = omega + alpha*y_{t-1}^2 + beta_*sigma_{t-1}^2.\n",
    "    \"\"\"\n",
    "    T = len(eps)\n",
    "    sigma2 = np.zeros(T, float)\n",
    "    y = np.zeros(T, float)\n",
    "    # Initialize at unconditional variance if stationary\n",
    "    sigma2[0] = omega / max(1e-12, (1.0 - alpha - beta_)) if (alpha + beta_ < 0.999) else np.var(eps)\n",
    "    y[0] = np.sqrt(sigma2[0]) * eps[0]\n",
    "    for t in range(1, T):\n",
    "        sigma2[t] = omega + alpha * y[t-1]**2 + beta_ * sigma2[t-1]\n",
    "        sigma2[t] = max(sigma2[t], 1e-12)\n",
    "        y[t] = np.sqrt(sigma2[t]) * eps[t]\n",
    "    return y, sigma2\n",
    "\n",
    "def beta_mean_std(a, b):\n",
    "    \"\"\"Return (mean, std) of Beta(a,b).\"\"\"\n",
    "    mu = a / (a + b)\n",
    "    var = (a * b) / ((a + b) ** 2 * (a + b + 1))\n",
    "    return mu, np.sqrt(var)\n",
    "\n",
    "# STABLE BETA-MLE OBJECTIVE (finite everywhere)\n",
    "\n",
    "def _reconstruct_sigma2(y, omega, alpha, beta_):\n",
    "    \"\"\"Internal recursion with defensive floors.\"\"\"\n",
    "    y = np.asarray(y, float)\n",
    "    T = len(y)\n",
    "    s2 = np.zeros(T, float)\n",
    "    s2[0] = (omega / max(1e-12, 1 - alpha - beta_)) if (alpha + beta_ < 0.999) else np.var(y)\n",
    "    for t in range(1, T):\n",
    "        s2[t] = omega + alpha * y[t-1]**2 + beta_ * s2[t-1]\n",
    "        if not np.isfinite(s2[t]) or s2[t] <= 0:\n",
    "            s2[t] = 1e-12\n",
    "    return s2\n",
    "\n",
    "def beta_mle_negloglik(theta, y, penalty_scale=1e6):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for Beta-innovation GARCH with *finite* soft penalty\n",
    "    outside support. Always returns a finite float for optimizer stability.\n",
    "    theta = (omega, alpha, beta_, a, b)\n",
    "    \"\"\"\n",
    "    omega, alpha, beta_, a, b = map(float, theta)\n",
    "    # Basic feasibility checks (still hard)\n",
    "    if (omega <= 0) or (alpha < 0) or (beta_ < 0) or (alpha + beta_ >= 1 - 5e-3) or (a <= 0) or (b <= 0):\n",
    "        # Large but finite penalty\n",
    "        return penalty_scale * 1e4\n",
    "\n",
    "    y = np.asarray(y, float)\n",
    "    T = len(y)\n",
    "\n",
    "    # GARCH variance\n",
    "    sigma2 = _reconstruct_sigma2(y, omega, alpha, beta_)\n",
    "    sigma_t = np.sqrt(np.maximum(sigma2, 1e-12))\n",
    "\n",
    "    # Map standardized residuals to Beta support\n",
    "    mu_w, sigma_w = beta_mean_std(a, b)\n",
    "    # Avoid degenerate sigma_w\n",
    "    sigma_w = max(sigma_w, 1e-8)\n",
    "\n",
    "    z = y / sigma_t\n",
    "    beta_arg = mu_w + sigma_w * z\n",
    "\n",
    "    # Soft penalty for out-of-support values (finite)\n",
    "    outside_lo = beta_arg <= 0\n",
    "    outside_hi = beta_arg >= 1\n",
    "    if np.any(outside_lo) or np.any(outside_hi):\n",
    "        dist = np.zeros_like(beta_arg)\n",
    "        dist[outside_lo] = -beta_arg[outside_lo]\n",
    "        dist[outside_hi] = beta_arg[outside_hi] - 1.0\n",
    "        # Quadratic distance + linear count penalty\n",
    "        return penalty_scale * (np.sum(dist**2) + 0.01 * (outside_lo.sum() + outside_hi.sum()))\n",
    "\n",
    "    # Stable logs\n",
    "    eps = 1e-12\n",
    "    beta_arg = np.clip(beta_arg, eps, 1 - eps)\n",
    "    # loglike up to additive constants\n",
    "    loglike = (\n",
    "        (a - 1.0) * np.log(beta_arg)\n",
    "        + (b - 1.0) * np.log1p(-beta_arg)\n",
    "        - betaln(a, b)\n",
    "        + np.log(sigma_w)\n",
    "        - np.log(sigma_t)\n",
    "    )\n",
    "    nll = -np.sum(loglike)\n",
    "    # Guard against NaNs\n",
    "    if not np.isfinite(nll):\n",
    "        return penalty_scale * 1e4\n",
    "    return nll\n",
    "\n",
    "# ESTIMATION ROUTINES (SLSQP Optimization Algorithm for Beta-MLE)\n",
    "\n",
    "# --- QMLE (Gaussian) ---\n",
    "def estimate_qmle(y):\n",
    "    \"\"\"Return [omega, alpha, beta] using arch (Gaussian QMLE).\"\"\"\n",
    "    try:\n",
    "        model = arch_model(y, mean='zero', vol='GARCH', p=1, q=1, dist='normal')\n",
    "        res = model.fit(disp='off', show_warning=False)\n",
    "        p = res.params\n",
    "        return [float(p['omega']), float(p['alpha[1]']), float(p['beta[1]'])]\n",
    "    except Exception:\n",
    "        return [np.nan, np.nan, np.nan]\n",
    "\n",
    "# --- t-MLE (via arch) ---\n",
    "def estimate_t_mle(y):\n",
    "    \"\"\"Return [omega, alpha, beta, df] using arch (Student-t).\"\"\"\n",
    "    model = arch_model(y, mean='zero', vol='GARCH', p=1, q=1, dist='t')\n",
    "    res = model.fit(disp='off', show_warning=False)\n",
    "    p = res.params\n",
    "    return [float(p['omega']), float(p['alpha[1]']), float(p['beta[1]']), float(p['nu'])]\n",
    "\n",
    "# --- Beta-MLE (robust SLSQP) ---\n",
    "def _project_stationary(alpha, beta_, margin=0.02):\n",
    "    \"\"\"Ensure alpha+beta <= 1 - margin.\"\"\"\n",
    "    s = alpha + beta_\n",
    "    cap = 1.0 - margin\n",
    "    if s >= cap:\n",
    "        if s <= 1e-12:\n",
    "            return max(alpha, 1e-6), max(beta_, 1e-6)\n",
    "        scale = cap / s\n",
    "        return max(alpha * scale, 1e-6), max(beta_ * scale, 1e-6)\n",
    "    return max(alpha, 1e-6), max(beta_, 1e-6)\n",
    "\n",
    "def estimate_beta_mle(y, theta0=None, bounds=None, restarts=5, seed=2025):\n",
    "    \"\"\"\n",
    "    SLSQP with:\n",
    "      - strictly feasible warm-start (uses QMLE for omega,alpha,beta)\n",
    "      - margin on stationarity (alpha+beta <= 1-5e-3)\n",
    "      - large upper bounds for a,b to widen admissible z-range\n",
    "      - finite soft penalties in the objective\n",
    "      - random restarts if the first try fails\n",
    "    Returns [omega, alpha, beta, a, b] or None.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y = np.asarray(y, float)\n",
    "\n",
    "    # Bounds (can be tweaked)\n",
    "    if bounds is None:\n",
    "        bounds = [\n",
    "            (1e-8, None),          # omega > 0\n",
    "            (1e-8, 1.0 - 5e-3),    # alpha >= 0\n",
    "            (1e-8, 1.0 - 5e-3),    # beta  >= 0\n",
    "            (1.0, 300.0),          # a >= 1, allow large\n",
    "            (1.0, 300.0)           # b >= 1\n",
    "        ]\n",
    "\n",
    "    # Warm-start: QMLE for (omega,alpha,beta), large a,b init\n",
    "    if theta0 is None:\n",
    "        om, al, be = estimate_qmle(y)\n",
    "        # Safe defaults if QMLE fails\n",
    "        if not np.isfinite(om): om = np.var(y) * 0.05\n",
    "        if not np.isfinite(al): al = 0.05\n",
    "        if not np.isfinite(be): be = 0.90\n",
    "        al, be = _project_stationary(al, be, margin=0.02)\n",
    "        a0, b0 = 20.0, 20.0       # generous a,b so sigma_w is small => wide z-range\n",
    "        theta0 = np.array([om, al, be, a0, b0], float)\n",
    "    else:\n",
    "        theta0 = np.array(theta0, float)\n",
    "        theta0[1], theta0[2] = _project_stationary(theta0[1], theta0[2], margin=0.02)\n",
    "        theta0[0] = max(theta0[0], 1e-8)\n",
    "        theta0[3] = max(theta0[3], 1.0)\n",
    "        theta0[4] = max(theta0[4], 1.0)\n",
    "\n",
    "    # Nonlinear stationarity constraint with margin\n",
    "    nlc = {'type': 'ineq', 'fun': lambda th: (1.0 - 5e-3) - (th[1] + th[2])}\n",
    "\n",
    "    def _run_once(th0):\n",
    "        res = minimize(\n",
    "            beta_mle_negloglik, th0, args=(y,),\n",
    "            method='SLSQP',\n",
    "            bounds=bounds,\n",
    "            constraints=[nlc],\n",
    "            options={'maxiter': 2000, 'ftol': 1e-9, 'eps': 1e-6, 'disp': False}\n",
    "        )\n",
    "        return res\n",
    "\n",
    "    # Try initial run\n",
    "    best = None\n",
    "    res = _run_once(theta0)\n",
    "    if res.success and np.isfinite(res.fun):\n",
    "        best = res\n",
    "\n",
    "    # Random restarts around feasible region\n",
    "    for _ in range(restarts):\n",
    "        th = theta0.copy()\n",
    "        # jitter omega, alpha, beta mildly\n",
    "        th[:3] *= rng.uniform(0.7, 1.3, size=3)\n",
    "        th[1], th[2] = _project_stationary(th[1], th[2], margin=0.02)\n",
    "        # restart a,b in a wide box\n",
    "        th[3:] = rng.uniform(5.0, 60.0, size=2)\n",
    "        res2 = _run_once(th)\n",
    "        if res2.success and np.isfinite(res2.fun):\n",
    "            if (best is None) or (res2.fun < best.fun):\n",
    "                best = res2\n",
    "\n",
    "    if best is not None:\n",
    "        return list(best.x)\n",
    "    # Last resort: return None so caller can record NaNs\n",
    "    print(\"Beta-MLE Optimization failed:\", res.message if res is not None else \"unknown\")\n",
    "    return None\n",
    "\n",
    "# EXPERIMENT DESIGN\n",
    "\n",
    "GARCH_PARAMS = {\n",
    "    'A': (0.10, 0.10, 0.80),  # High persistence\n",
    "    'B': (0.05, 0.05, 0.90),  # Very high persistence\n",
    "    'C': (0.20, 0.15, 0.70),  # Moderate persistence\n",
    "}\n",
    "\n",
    "INNOVATIONS = [\n",
    "    ('Beta', (2, 5)),\n",
    "    ('Beta', (5, 2)),\n",
    "    ('Beta', (3, 3)),\n",
    "    ('t', 3),\n",
    "    ('t', 8),\n",
    "    ('t', 12),\n",
    "    ('normal', None)\n",
    "]\n",
    "\n",
    "T = 1000   # series length\n",
    "N = 1000    # replications number\n",
    "\n",
    "# 5) SIMULATION + ESTIMATION LOOP\n",
    "\n",
    "start_time = time.time()\n",
    "all_results = []\n",
    "\n",
    "for case, (omega, alpha, beta_) in GARCH_PARAMS.items():\n",
    "    for innov_type, innov_param in INNOVATIONS:\n",
    "        print(f\"\\nStarting {case}-{innov_type}-{innov_param}\")\n",
    "        for rep in range(N):\n",
    "            # --- Innovations\n",
    "            if innov_type == 'Beta':\n",
    "                a, b = innov_param\n",
    "                eps = standardized_beta_sample(a, b, T)\n",
    "            elif innov_type == 't':\n",
    "                df = innov_param\n",
    "                eps = standardized_t_sample(df, T)\n",
    "            else:\n",
    "                eps = np.random.normal(0.0, 1.0, T)\n",
    "\n",
    "            # --- Simulate\n",
    "            y, sigma2 = simulate_garch(omega, alpha, beta_, eps)\n",
    "\n",
    "            # --- Beta-MLE (robust SLSQP)\n",
    "            theta0_beta = [omega, alpha, beta_, 20.0, 20.0]  # generous start for a,b\n",
    "            beta_est = estimate_beta_mle(y, theta0=theta0_beta)\n",
    "            if beta_est is None:\n",
    "                beta_est = [np.nan]*5\n",
    "\n",
    "            # --- t-MLE & QMLE (arch)\n",
    "            try:\n",
    "                o_t, a_t, b_t, nu_t = estimate_t_mle(y)\n",
    "            except Exception:\n",
    "                o_t, a_t, b_t, nu_t = [np.nan]*4\n",
    "\n",
    "            o_q, a_q, b_q = estimate_qmle(y)\n",
    "\n",
    "            # --- Store\n",
    "            all_results.append({\n",
    "                'case': case,\n",
    "                'innov_type': innov_type,\n",
    "                'innov_param': str(innov_param),\n",
    "                'rep': rep,\n",
    "                'omega_true': omega, 'alpha_true': alpha, 'beta_true': beta_,\n",
    "                'a_true': innov_param[0] if innov_type == 'Beta' else np.nan,\n",
    "                'b_true': innov_param[1] if innov_type == 'Beta' else np.nan,\n",
    "                'df_true': innov_param if innov_type == 't' else np.nan,\n",
    "                'omega_beta': beta_est[0], 'alpha_beta': beta_est[1], 'beta_beta': beta_est[2],\n",
    "                'a_beta': beta_est[3], 'b_beta': beta_est[4],\n",
    "                'omega_t': o_t, 'alpha_t': a_t, 'beta_t': b_t, 'df_t': nu_t,\n",
    "                'omega_qmle': o_q, 'alpha_qmle': a_q, 'beta_qmle': b_q,\n",
    "                'y_series': y.tolist(),\n",
    "                'sigma2_true': sigma2.tolist()\n",
    "            })\n",
    "\n",
    "        elapsed = (time.time() - start_time)/60\n",
    "        print(f\"  Completed {N}/{N} replications ({elapsed:.1f} min elapsed)\")\n",
    "\n",
    "print(\"\\nSimulation complete! Results in `all_results`.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('module://matplotlib_inline.backend_inline')  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _beta_ok(row):\n",
    "    return np.all(np.isfinite([\n",
    "        row['omega_beta'], row['alpha_beta'], row['beta_beta'],\n",
    "        row['a_beta'], row['b_beta']\n",
    "    ]))\n",
    "\n",
    "# Pick a specific row by replication index and use the moderate GARCH model parameter setting, case C\n",
    "def rows_for_fixed_rep(all_results, targets, case='A', rep=0, require_beta=True):\n",
    "    rows = []\n",
    "    failures = []\n",
    "\n",
    "    # Try to fetch exactly that rep for each target\n",
    "    for itype, iparam in targets:\n",
    "        target = str(iparam)\n",
    "        match = [r for r in all_results\n",
    "                 if r['case'] == case\n",
    "                 and r['innov_type'] == itype\n",
    "                 and r['innov_param'] == target\n",
    "                 and r['rep'] == rep]\n",
    "        if not match:\n",
    "            failures.append((itype, iparam, 'missing'))\n",
    "            continue\n",
    "        row = match[0]\n",
    "        if require_beta and itype is not None and not _beta_ok(row):\n",
    "            failures.append((itype, iparam, 'beta_fail'))\n",
    "        else:\n",
    "            rows.append(row)\n",
    "\n",
    "    if failures:\n",
    "        avail = {}\n",
    "        for itype, iparam in targets:\n",
    "            target = str(iparam)\n",
    "            reps_ok = sorted({\n",
    "                r['rep'] for r in all_results\n",
    "                if r['case'] == case\n",
    "                and r['innov_type'] == itype\n",
    "                and r['innov_param'] == target\n",
    "                and (not require_beta or _beta_ok(r))\n",
    "            })\n",
    "            avail[(itype, target)] = reps_ok\n",
    "        common = sorted(set.intersection(*(set(v) for v in avail.values()))) if avail else []\n",
    "\n",
    "        msg = [\n",
    "            f\"[rows_for_fixed_rep] Requested rep={rep} is not usable for all targets.\",\n",
    "            f\"  Failures (type, param, reason): {failures}\",\n",
    "            f\"  Common reps with success across ALL targets: {common if common else 'None'}\",\n",
    "            \"  Per-target available reps:\",\n",
    "        ]\n",
    "        for k, v in avail.items():\n",
    "            msg.append(f\"    {k}: {v if v else 'None'}\")\n",
    "        raise RuntimeError(\"\\n\".join(msg))\n",
    "\n",
    "    return rep, rows\n",
    "# Function to obtain the simulated(true) volatility or estimated volatility\n",
    "def reconstruct_sigma2(y, omega, alpha, beta_):\n",
    "    y = np.asarray(y, float)\n",
    "    T = len(y)\n",
    "    s2 = np.zeros(T, float)\n",
    "    s2[0] = (omega/(1 - alpha - beta_)) if (alpha + beta_ < 0.999) else np.var(y)\n",
    "    for t in range(1, T):\n",
    "        s2[t] = omega + alpha*y[t-1]**2 + beta_*s2[t-1]\n",
    "    return np.maximum(s2, 1e-12)\n",
    "# There are different ways to construct errors used to construct estimated returns, we use the true shocks in our comparison, because it is more suitable for estimation performance comparison under different innovations\n",
    "def build_bundle(row, eps_source=\"true\", ref_model=\"QMLE\"):\n",
    "    y = np.asarray(row['y_series'], float)\n",
    "\n",
    "    # true volatility & shocks\n",
    "    s_true = np.sqrt(reconstruct_sigma2(y, row['omega_true'], row['alpha_true'], row['beta_true']))\n",
    "    if eps_source == \"true\":\n",
    "        eps = y / s_true\n",
    "\n",
    "    s_hat = {}\n",
    "    # Beta‑MLE\n",
    "    if all(np.isfinite([row['omega_beta'], row['alpha_beta'], row['beta_beta']])):\n",
    "        s_hat['Beta‑MLE'] = np.sqrt(reconstruct_sigma2(y, row['omega_beta'], row['alpha_beta'], row['beta_beta']))\n",
    "    # t‑MLE\n",
    "    s_hat['t‑MLE'] = np.sqrt(reconstruct_sigma2(y, row['omega_t'], row['alpha_t'], row['beta_t']))\n",
    "    # QMLE\n",
    "    s_hat['QMLE']  = np.sqrt(reconstruct_sigma2(y, row['omega_qmle'], row['alpha_qmle'], row['beta_qmle']))\n",
    "\n",
    "    if eps_source == \"ref\":\n",
    "        s_ref = s_hat[ref_model]\n",
    "        eps = y / s_ref\n",
    "\n",
    "    # estimated return series\n",
    "    y_hat = {name: s * eps for name, s in s_hat.items()}\n",
    "\n",
    "    return dict(y_true=y, s_true=s_true, y_hat=y_hat, s_hat=s_hat)\n",
    "# Compute RMSE\n",
    "def rmse(a, b):\n",
    "    a = np.asarray(a); b = np.asarray(b)\n",
    "    return float(np.sqrt(np.mean((a-b)**2)))\n",
    "\n",
    "def print_rmse(bundle):\n",
    "    y_true = bundle['y_true']; s_true = bundle['s_true']\n",
    "    print(\"RMSE vs True  |  returns (y_t)   volatility (sigma_t)\")\n",
    "    for k in bundle['y_hat'].keys():\n",
    "        r1 = rmse(y_true, bundle['y_hat'][k])\n",
    "        r2 = rmse(s_true, bundle['s_hat'][k])\n",
    "        print(f\"{k:10s}    {r1:10.4f}        {r2:10.4f}\")\n",
    "label_map = {\n",
    "    'Beta‑MLE': 'Beta-(Q)MLE',\n",
    "    't‑MLE': 't-(Q)MLE',\n",
    "    'QMLE': 'Gaussian-(Q)MLE',\n",
    "}\n",
    "# Plot function\n",
    "def plot_two_panel(row, bundle, shock_label=\"true\"):\n",
    "    T = len(bundle['y_true']); tgrid = np.arange(T)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 3.8), constrained_layout=True)\n",
    "\n",
    "    # Returns\n",
    "    ax = axes[0]\n",
    "    ax.plot(tgrid, bundle['y_true'], lw=1.2, label='True')\n",
    "    for k, yhat in bundle['y_hat'].items():\n",
    "        ax.plot(tgrid, yhat, lw=0.9, label=k)\n",
    "    ax.set_title(f\"Returns: True vs estimated\")\n",
    "    ax.set_xlabel(\"t\"); ax.set_ylabel(\"y_t\")\n",
    "    ax.legend(ncols=2, fontsize=8, frameon=False)\n",
    "\n",
    "    # Volatility\n",
    "    ax = axes[1]\n",
    "    ax.plot(tgrid, bundle['s_true'], lw=1.2, label='True')\n",
    "    for k, yhat in bundle['y_hat'].items():\n",
    "        label = label_map.get(k, k)  \n",
    "        ax.plot(tgrid, yhat, lw=0.9, label=label)\n",
    "    ax.set_title(\"Volatility: True vs estimated (σ_t)\")\n",
    "    ax.set_xlabel(\"t\"); ax.set_ylabel(\"σ_t\")\n",
    "    ax.legend(ncols=2, fontsize=8, frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "# The targets (order matters; plots will follow this order)\n",
    "targets = [\n",
    "    ('Beta',   (2, 5)),\n",
    "    ('t',      3),\n",
    "    ('normal', None),\n",
    "]\n",
    "\n",
    "# Choose the exact realization you want:\n",
    "np.random.seed(198)\n",
    "fix_rep = np.random.randint(0, 301)\n",
    "\n",
    "# Get rows for that fixed rep (requires Beta‑MLE success by default)\n",
    "rep, rows = rows_for_fixed_rep(all_results, targets, case='A', rep=fix_rep, require_beta=True)\n",
    "print(f\"Using fixed rep = {rep}\")\n",
    "\n",
    "# Plot each target using true ε_t \n",
    "for r in rows:\n",
    "    bundle = build_bundle(r, eps_source=\"true\")\n",
    "    print_rmse(bundle)\n",
    "    plot_two_panel(r, bundle, shock_label=f\"true (rep={rep})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- new plot function: volatility only ---\n",
    "def plot_volatility_only(bundle, rep=None, innov_label=None):\n",
    "    T = len(bundle['s_true'])\n",
    "    t = np.arange(T)\n",
    "\n",
    "    plt.figure(figsize=(7.6, 3.6))\n",
    "    # true path\n",
    "    plt.plot(t, bundle['s_true'], lw=1.2, label='True')\n",
    "    # estimated paths\n",
    "    for name, s in bundle['s_hat'].items():\n",
    "        plt.plot(t, s, lw=0.9, label=name,alpha = 0.8)\n",
    "\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(r\"$\\sigma_t$\")\n",
    "    plt.legend(ncols=2, fontsize=8, frameon=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- choose targets and replication as before ---\n",
    "targets = [\n",
    "    ('Beta',   (2, 5)),\n",
    "    ('t',      3),\n",
    "    ('normal', None),\n",
    "]\n",
    "\n",
    "np.random.seed(198)\n",
    "fix_rep = np.random.randint(0, 301)\n",
    "\n",
    "# --- fetch rows for that replication (requires Beta-MLE success by default) ---\n",
    "rep, rows = rows_for_fixed_rep(all_results, targets, case='A', rep=fix_rep, require_beta=True)\n",
    "\n",
    "# --- build and plot (no RMSE, no returns panel) ---\n",
    "for r in rows:\n",
    "    bundle = build_bundle(r, eps_source=\"true\")  # eps doesn't matter for volatility\n",
    "    label = f\"{r['innov_type']} innovation, param={r['innov_param']}\"\n",
    "    plot_volatility_only(bundle, rep=rep, innov_label=label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('PDF') \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_volatility_only(bundle, rep=None, innov_label=None):\n",
    "    T = len(bundle['s_true'])\n",
    "    t = np.arange(T)\n",
    "\n",
    "    plt.figure(figsize=(7.6, 3.6))\n",
    "    plt.plot(t, bundle['s_true'], lw=1.5, label='True')  \n",
    "    \n",
    "    for name, s in bundle['s_hat'].items():\n",
    "        plt.plot(t, s, lw=0.9, label=name, alpha=0.8)\n",
    "\n",
    "    plt.xlabel(\"t\", fontsize=13)\n",
    "    plt.ylabel(\"$\\sigma_t$\",fontsize=13)  \n",
    "    plt.legend(ncols=2, fontsize=10, frameon=False)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"volatility_rep{rep}_{innov_label.replace(' ', '_')}.pdf\"\n",
    "    plt.savefig(filename) \n",
    "    plt.close()  \n",
    "\n",
    "targets = [\n",
    "    ('Beta', (2, 5)),\n",
    "    ('t', 3),\n",
    "    ('normal', None),\n",
    "]\n",
    "\n",
    "np.random.seed(198)\n",
    "fix_rep = np.random.randint(0, 301)\n",
    "\n",
    "rep, rows = rows_for_fixed_rep(all_results, targets, case='A', rep=fix_rep, require_beta=True)\n",
    "\n",
    "for r in rows:\n",
    "    bundle = build_bundle(r, eps_source=\"true\")\n",
    "    plot_volatility_only(bundle, rep=rep, innov_label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# RMSE and NRMSE\n",
    "ESTIMATOR_FIELDS = {\n",
    "    \"Beta-MLE\":      (\"omega_beta\",  \"alpha_beta\",  \"beta_beta\"),\n",
    "    \"t-MLE\":         (\"omega_t\",     \"alpha_t\",     \"beta_t\"),\n",
    "    \"Gaussian-QMLE\": (\"omega_qmle\",  \"alpha_qmle\",  \"beta_qmle\"),\n",
    "}\n",
    "PARAMS = (\"omega\", \"alpha\", \"beta\")\n",
    "\n",
    "def _safe_num(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "def beta_fit_ok(rec, c_var=50.0, c_true=100.0): # Return False if the Beta-MLE estimate is clearly bad.\n",
    "    try:\n",
    "        om = float(rec.get('omega_beta'))\n",
    "        a  = float(rec.get('alpha_beta'))\n",
    "        b  = float(rec.get('beta_beta'))\n",
    "        aa = float(rec.get('a_beta'))\n",
    "        bb = float(rec.get('b_beta'))\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "    if not np.all(np.isfinite([om, a, b, aa, bb])): return False\n",
    "    if om <= 0 or a < 0 or b < 0 or a + b >= 1 - 1e-6 or aa <= 0 or bb <= 0: return False\n",
    "\n",
    "    y = np.asarray(rec.get('y_series'), float)\n",
    "    var_y = float(np.var(y)) if np.isfinite(np.var(y)) else 1.0\n",
    "    if om > c_var * max(var_y, 1e-8):   # too big for the data scale\n",
    "        return False\n",
    "\n",
    "    om_true = rec.get('omega_true')\n",
    "    if np.isfinite(om_true) and om > c_true * max(float(om_true), 1e-8):  # too big vs truth\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "def _collect_errors_long(all_results): # Construct the table \n",
    "    fail_count = defaultdict(int)\n",
    "    total_count = defaultdict(int)\n",
    "\n",
    "    rows = []\n",
    "    for rec in all_results:\n",
    "        key = (rec['case'], rec['innov_type'], rec['innov_param'], 'Beta-MLE')\n",
    "        if rec['innov_type'] == 't':\n",
    "            total_count[key] += 1\n",
    "            if not beta_fit_ok(rec):\n",
    "                fail_count[key] += 1\n",
    "                continue # handle strange/extreme values\n",
    "        case = rec.get('case')\n",
    "        itype = rec.get('innov_type')\n",
    "        iparam = rec.get('innov_param')\n",
    "        rep = rec.get('rep')\n",
    "\n",
    "        omega_true = _safe_num(rec.get('omega_true'))\n",
    "        alpha_true = _safe_num(rec.get('alpha_true'))\n",
    "        beta_true  = _safe_num(rec.get('beta_true'))\n",
    "\n",
    "        for est, (k_om, k_al, k_be) in ESTIMATOR_FIELDS.items():\n",
    "            om_hat = _safe_num(rec.get(k_om))\n",
    "            al_hat = _safe_num(rec.get(k_al))\n",
    "            be_hat = _safe_num(rec.get(k_be))\n",
    "\n",
    "            # consider NaN situation\n",
    "            if not np.any(np.isfinite([om_hat, al_hat, be_hat])):\n",
    "                continue\n",
    "\n",
    "            rows.append({\n",
    "                'case': case, 'innov_type': itype, 'innov_param': iparam, 'rep': rep,\n",
    "                'estimator': est,\n",
    "                'err_omega': om_hat - omega_true,\n",
    "                'err_alpha': al_hat - alpha_true,\n",
    "                'err_beta' : be_hat  - beta_true,\n",
    "                'true_omega': omega_true, 'true_alpha': alpha_true, 'true_beta': beta_true\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def _rmse(arr):\n",
    "    x = pd.Series(arr, dtype=float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.empty: return np.nan\n",
    "    return float(np.sqrt(np.mean(np.square(x))))\n",
    "\n",
    "def compute_rmse_table(all_results):\n",
    "    df = _collect_errors_long(all_results)\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\n",
    "            'case','innov_type','innov_param','estimator',\n",
    "            'rmse_omega','rmse_alpha','rmse_beta'\n",
    "        ])\n",
    "    rmse_tbl = (df.groupby(['case','innov_type','innov_param','estimator'], dropna=False)\n",
    "                  .agg(rmse_omega=('err_omega', _rmse),\n",
    "                       rmse_alpha=('err_alpha', _rmse),\n",
    "                       rmse_beta =('err_beta',  _rmse))\n",
    "                  .reset_index())\n",
    "    return rmse_tbl\n",
    "\n",
    "def compute_nrmse_table(all_results, eps=1e-12):\n",
    "    df = _collect_errors_long(all_results)\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\n",
    "            'case','innov_type','innov_param','estimator',\n",
    "            'nrmse_omega','nrmse_alpha','nrmse_beta'\n",
    "        ])\n",
    "\n",
    "    rmse_tbl = compute_rmse_table(all_results)\n",
    "\n",
    "    # Ture value for those three parameters, omega, alpha, beta\n",
    "    tru = (df.groupby(['case','innov_type','innov_param'], dropna=False)\n",
    "             .agg(true_omega=('true_omega','first'),\n",
    "                  true_alpha=('true_alpha','first'),\n",
    "                  true_beta =('true_beta','first'))\n",
    "             .reset_index())\n",
    "\n",
    "    out = rmse_tbl.merge(tru, on=['case','innov_type','innov_param'], how='left')\n",
    "\n",
    "    def _nrmse(rmse, true_val):\n",
    "        if not np.isfinite(rmse) or not np.isfinite(true_val): return np.nan\n",
    "        denom = abs(true_val)\n",
    "        return float(rmse if denom < eps else rmse / denom)\n",
    "\n",
    "    out['nrmse_omega'] = out.apply(lambda r: _nrmse(r['rmse_omega'], r['true_omega']), axis=1)\n",
    "    out['nrmse_alpha'] = out.apply(lambda r: _nrmse(r['rmse_alpha'], r['true_alpha']), axis=1)\n",
    "    out['nrmse_beta']  = out.apply(lambda r: _nrmse(r['rmse_beta'],  r['true_beta']),  axis=1)\n",
    "\n",
    "    return out[['case','innov_type','innov_param','estimator',\n",
    "                'nrmse_omega','nrmse_alpha','nrmse_beta']]\n",
    "\n",
    "rmse_table  = compute_rmse_table(all_results)\n",
    "nrmse_table = compute_nrmse_table(all_results)\n",
    "\n",
    "# print(\"RMSE by setting × estimator:\")\n",
    "# print(rmse_table.sort_values(['case','innov_type','innov_param','estimator']).head(12))\n",
    "\n",
    "# print(\"\\nNRMSE by setting × estimator:\")\n",
    "# print(nrmse_table.sort_values(['case','innov_type','innov_param','estimator']).head(12))\n",
    "# Print the result for each estimator one by one\n",
    "pivot_nrmse_omega = (nrmse_table\n",
    "    .pivot(index=['case','innov_type','innov_param'], columns='estimator', values='nrmse_omega'))\n",
    "print(\"\\nPivot: NRMSE(omega) per setting:\")\n",
    "print(pivot_nrmse_omega)\n",
    "\n",
    "pivot_nrmse_alpha = (nrmse_table\n",
    "    .pivot(index=['case','innov_type','innov_param'], columns='estimator', values='nrmse_alpha'))\n",
    "print(\"\\nPivot: NRMSE(alpha) per setting:\")\n",
    "print(pivot_nrmse_alpha)\n",
    "\n",
    "pivot_nrmse_beta = (nrmse_table\n",
    "    .pivot(index=['case','innov_type','innov_param'], columns='estimator', values='nrmse_beta'))\n",
    "print(\"\\nPivot: NRMSE(beta) per setting:\")\n",
    "print(pivot_nrmse_beta)\n",
    "\n",
    "pivot_rmse_omega = (rmse_table\n",
    "    .pivot(index=['case','innov_type','innov_param'], columns='estimator', values='rmse_omega'))\n",
    "print(\"\\nPivot: RMSE(omega) per setting:\")\n",
    "print(pivot_rmse_omega)\n",
    "\n",
    "pivot_rmse_alpha = (rmse_table\n",
    "    .pivot(index=['case','innov_type','innov_param'], columns='estimator', values='rmse_alpha'))\n",
    "print(\"\\nPivot: RMSE(alpha) per setting:\")\n",
    "print(pivot_nrmse_alpha)\n",
    "\n",
    "pivot_rmse_beta = (rmse_table\n",
    "    .pivot(index=['case','innov_type','innov_param'], columns='estimator', values='rmse_beta'))\n",
    "print(\"\\nPivot: RMSE(beta) per setting:\")\n",
    "print(pivot_nrmse_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "def beta_mean_std(a, b):\n",
    "    a = float(a); b = float(b)\n",
    "    mu = a / (a + b)\n",
    "    var = (a * b) / ((a + b)**2 * (a + b + 1.0))\n",
    "    return mu, float(np.sqrt(max(var, 0.0)))\n",
    "\n",
    "def _reconstruct_sigma2(y, omega, alpha, beta_):\n",
    "    # Standard GARCH(1,1) recursion for conditional variance.\n",
    "    y = np.asarray(y, float)\n",
    "    T = y.shape[0]\n",
    "    s2 = np.empty(T, dtype=float)\n",
    "    ab = alpha + beta_\n",
    "    s2_0 = omega / (1.0 - ab) if (omega > 0 and 0 <= ab < 1.0) else max(y[0]**2, omega)\n",
    "    s2[0] = float(max(s2_0, 1e-12))\n",
    "    for t in range(1, T):\n",
    "        s2[t] = omega + alpha * y[t-1]**2 + beta_ * s2[t-1]\n",
    "        if not np.isfinite(s2[t]): s2[t] = 1e6\n",
    "    return s2\n",
    "\n",
    "def beta_mle_negloglik(theta, y, penalty_scale=1e6):\n",
    "    omega, alpha, beta_, a, b = map(float, theta)\n",
    "    y = np.asarray(y, float)\n",
    "\n",
    "    # base penalties (positivity, stationarity-ish)\n",
    "    pen = 0.0\n",
    "    if omega <= 0: pen += (1 - 1e-6 - omega)**2\n",
    "    if alpha < 0:  pen += (0 - alpha)**2\n",
    "    if beta_ < 0:  pen += (0 - beta_)**2\n",
    "    if a <= 0:     pen += (1 - 1e-6 - a)**2\n",
    "    if b <= 0:     pen += (1 - 1e-6 - b)**2\n",
    "    if alpha + beta_ >= 1 - 5e-3:\n",
    "        pen += (alpha + beta_ - (1 - 5e-3))**2 * 1e2  # stronger near unit root\n",
    "\n",
    "    s2 = _reconstruct_sigma2(y, omega, alpha, beta_)\n",
    "    sig = np.sqrt(np.maximum(s2, 1e-12))\n",
    "    mu_w, sd_w = beta_mean_std(a, b)\n",
    "    sd_w = max(sd_w, 1e-8)\n",
    "\n",
    "    z = y / sig\n",
    "    w = mu_w + sd_w * z\n",
    "\n",
    "    # soft barrier for w ∈ (0,1)\n",
    "    # outside (0,1) add quadratic distance * big weight; inside clip for log\n",
    "    dist_left  = np.maximum(0.0, 0.0 - w)\n",
    "    dist_right = np.maximum(0.0, w - 1.0)\n",
    "    pen += np.sum(dist_left**2 + dist_right**2) * 1e2\n",
    "\n",
    "    eps = 1e-12\n",
    "    w_clip = np.clip(w, eps, 1 - eps)\n",
    "\n",
    "    ll_terms = (\n",
    "        (a - 1.0) * np.log(w_clip)\n",
    "        + (b - 1.0) * np.log1p(-w_clip)\n",
    "        - betaln(a, b)\n",
    "        + np.log(sd_w)\n",
    "        - np.log(sig)\n",
    "    )\n",
    "    nll = -float(np.sum(ll_terms)) + penalty_scale * pen\n",
    "    return nll\n",
    "\n",
    "# SE for Beta-MLE\n",
    "def numerical_hessian(f, x, eps=2e-5): # epsilon is the Hessian step\n",
    "    x = np.asarray(x, float)\n",
    "    k = x.size\n",
    "    H = np.zeros((k, k), float)\n",
    "    for i in range(k):\n",
    "        for j in range(i, k):\n",
    "            ei = np.zeros_like(x); ei[i] = eps\n",
    "            ej = np.zeros_like(x); ej[j] = eps\n",
    "            fpp = f(x + ei + ej)\n",
    "            fpm = f(x + ei - ej)\n",
    "            fmp = f(x - ei + ej)\n",
    "            fmm = f(x - ei - ej)\n",
    "            H_ij = (fpp - fpm - fmp + fmm) / (4.0 * eps * eps)\n",
    "            H[i, j] = H_ij; H[j, i] = H_ij\n",
    "    return H\n",
    "\n",
    "def beta_se_from_hessian(y, theta):\n",
    "    # SEs from inverse Hessian of the penalized NLL at theta (length 5 → return first 3).\n",
    "    th = np.asarray(theta, float)\n",
    "    def nll(th_): return beta_mle_negloglik(th_, y, penalty_scale=1e6)\n",
    "    H = numerical_hessian(nll, th, eps=2e-5)\n",
    "    H = 0.5*(H + H.T) + 1e-8*np.eye(H.shape[0])  # symmetrize + tiny ridge\n",
    "    try:\n",
    "        cov = np.linalg.pinv(H)\n",
    "        se = np.sqrt(np.clip(np.diag(cov), 0, np.inf))\n",
    "    except LinAlgError:\n",
    "        se = np.full(th.shape[0], np.nan, float)\n",
    "    return se[:3]  # only (omega, alpha, beta)\n",
    "\n",
    "# SE from arch (QMLE / t) \n",
    "def arch_se_three(y, dist='normal'):\n",
    "    \"\"\"\n",
    "    Robust SEs [omega, alpha, beta] using 'arch' fit; returns NaNs if fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model = arch_model(y, mean='zero', vol='GARCH', p=1, q=1, dist=dist)\n",
    "        res = model.fit(disp='off', show_warning=False, cov_type='robust')\n",
    "        se = (res.std_err\n",
    "              .reindex(['omega','alpha[1]','beta[1]'])\n",
    "              .astype(float).to_numpy())\n",
    "        return se\n",
    "    except Exception:\n",
    "        return np.array([np.nan, np.nan, np.nan], float)\n",
    "\n",
    "# SE ratio computation \n",
    "    try: return float(x)\n",
    "    except Exception: return np.nan\n",
    "\n",
    "def _safe_ratio(num, den):\n",
    "    num = np.asarray(num, float); den = np.asarray(den, float)\n",
    "    out = np.full_like(num, np.nan, float)\n",
    "    ok = np.isfinite(num) & np.isfinite(den) & (den != 0)\n",
    "    out[ok] = num[ok] / den[ok]\n",
    "    return out\n",
    "\n",
    "def _safe_num(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def compute_se_ratio_tables(all_results):\n",
    "    rows_ratio = []   # per-rep ratios (for diagnostics/histograms)\n",
    "    rows_se    = []   # per-rep SEs for each estimator\n",
    "\n",
    "    for rec in all_results:\n",
    "        case, itype, iparam, rep = rec.get('case'), rec.get('innov_type'), rec.get('innov_param'), rec.get('rep')\n",
    "        y = np.asarray(rec.get('y_series'), float)\n",
    "\n",
    "        theta_beta = [\n",
    "            _safe_num(rec.get('omega_beta')),\n",
    "            _safe_num(rec.get('alpha_beta')),\n",
    "            _safe_num(rec.get('beta_beta')),\n",
    "            _safe_num(rec.get('a_beta')),\n",
    "            _safe_num(rec.get('b_beta')),\n",
    "        ]\n",
    "        if np.any(~np.isfinite(theta_beta)): # Consider NaN case, if can't compute Beta SE, then skip this replication\n",
    "            continue\n",
    "\n",
    "        se_beta = beta_se_from_hessian(y, theta_beta)   \n",
    "        se_q    = arch_se_three(y, dist='normal')\n",
    "        se_t    = arch_se_three(y, dist='t')\n",
    "\n",
    "        # store raw SEs per replication (used for \"ratio of means\")\n",
    "        rows_se.append({\n",
    "            'case': case, 'innov_type': itype, 'innov_param': iparam, 'rep': rep,\n",
    "            'se_omega_beta': se_beta[0], 'se_alpha_beta': se_beta[1], 'se_beta_beta': se_beta[2],\n",
    "            'se_omega_q': se_q[0],       'se_alpha_q': se_q[1],       'se_beta_q': se_q[2],\n",
    "            'se_omega_t': se_t[0],       'se_alpha_t': se_t[1],       'se_beta_t': se_t[2],\n",
    "        })\n",
    "\n",
    "        # Another indicator per-replication ratios \n",
    "        r_q = _safe_ratio(se_q, se_beta)\n",
    "        r_t = _safe_ratio(se_t, se_beta)\n",
    "        rows_ratio += [\n",
    "            {'case': case, 'innov_type': itype, 'innov_param': iparam, 'rep': rep,\n",
    "             'ratio_type': 'SEratio:QMLE/Beta',\n",
    "             'se_ratio_omega': r_q[0], 'se_ratio_alpha': r_q[1], 'se_ratio_beta': r_q[2]},\n",
    "            {'case': case, 'innov_type': itype, 'innov_param': iparam, 'rep': rep,\n",
    "             'ratio_type': 'SEratio:t/Beta',\n",
    "             'se_ratio_omega': r_t[0], 'se_ratio_alpha': r_t[1], 'se_ratio_beta': r_t[2]},\n",
    "        ]\n",
    "\n",
    "    seratio_long = pd.DataFrame(rows_ratio)\n",
    "    se_long      = pd.DataFrame(rows_se)\n",
    "\n",
    "    # Build panel as \"ratio of means\" \n",
    "    if se_long.empty:\n",
    "        seratio_panel = pd.DataFrame(columns=[\n",
    "            'case','innov_type','innov_param','ratio_type',\n",
    "            'avg_se_ratio_omega','avg_se_ratio_alpha','avg_se_ratio_beta'\n",
    "        ])\n",
    "    else:\n",
    "        keys = ['case','innov_type','innov_param']\n",
    "        mean_se = (se_long\n",
    "                   .groupby(keys, dropna=False)\n",
    "                   .mean(numeric_only=True)\n",
    "                   .reset_index())\n",
    "\n",
    "        def build_ratio(df, num, den, label):\n",
    "            return pd.DataFrame({\n",
    "                'case': df['case'], 'innov_type': df['innov_type'], 'innov_param': df['innov_param'],\n",
    "                'ratio_type': label,\n",
    "                'avg_se_ratio_omega': df[f'se_omega_{num}'] / df[f'se_omega_{den}'],\n",
    "                'avg_se_ratio_alpha': df[f'se_alpha_{num}'] / df[f'se_alpha_{den}'],\n",
    "                'avg_se_ratio_beta':  df[f'se_beta_{num}']  / df[f'se_beta_{den}'],\n",
    "            })\n",
    "\n",
    "        panel_q = build_ratio(mean_se, num='q',    den='beta', label='SEratio:QMLE/Beta')\n",
    "        panel_t = build_ratio(mean_se, num='t',    den='beta', label='SEratio:t/Beta')\n",
    "        seratio_panel = pd.concat([panel_q, panel_t], ignore_index=True)\n",
    "\n",
    "    return seratio_long, seratio_panel\n",
    "\n",
    "seratio_long, seratio_panel = compute_se_ratio_tables(all_results)\n",
    "\n",
    "print(\"SE ratio = (mean SE of estimator) / (mean SE of Beta)\")\n",
    "\n",
    "pivot_omega = (seratio_panel.pivot(index=['case','innov_type','innov_param'],\n",
    "                                   columns='ratio_type',\n",
    "                                   values='avg_se_ratio_omega')\n",
    "               .sort_index().round(4))\n",
    "pivot_alpha = (seratio_panel.pivot(index=['case','innov_type','innov_param'],\n",
    "                                   columns='ratio_type',\n",
    "                                   values='avg_se_ratio_alpha')\n",
    "               .sort_index().round(4))\n",
    "pivot_beta  = (seratio_panel.pivot(index=['case','innov_type','innov_param'],\n",
    "                                   columns='ratio_type',\n",
    "                                   values='avg_se_ratio_beta')\n",
    "               .sort_index().round(4))\n",
    "\n",
    "print(\"\\nPivot — SE ratio for ω (QMLE/Beta, t/Beta):\")\n",
    "print(pivot_omega)\n",
    "print(\"\\nPivot — SE ratio for α (QMLE/Beta, t/Beta):\")\n",
    "print(pivot_alpha)\n",
    "print(\"\\nPivot — SE ratio for β (QMLE/Beta, t/Beta):\")\n",
    "print(pivot_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "# Coverage\n",
    "def beta_mean_std(a, b):\n",
    "    a = float(a); b = float(b)\n",
    "    mu = a / (a + b)\n",
    "    var = (a * b) / ((a + b)**2 * (a + b + 1.0))\n",
    "    return mu, float(np.sqrt(max(var, 0.0)))\n",
    "\n",
    "def _reconstruct_sigma2(y, omega, alpha, beta_):\n",
    "    y = np.asarray(y, float)\n",
    "    T = y.shape[0]\n",
    "    s2 = np.empty(T, dtype=float)\n",
    "    ab = alpha + beta_\n",
    "    s2_0 = omega / (1.0 - ab) if (omega > 0 and 0 <= ab < 1.0) else max(y[0]**2, omega)\n",
    "    s2[0] = float(max(s2_0, 1e-12))\n",
    "    for t in range(1, T):\n",
    "        s2[t] = omega + alpha * y[t-1]**2 + beta_ * s2[t-1]\n",
    "        if not np.isfinite(s2[t]): s2[t] = 1e6\n",
    "    return s2\n",
    "\n",
    "def beta_mle_negloglik(theta, y, penalty_scale=1e6):\n",
    "    omega, alpha, beta_, a, b = map(float, theta)\n",
    "    y = np.asarray(y, float)\n",
    "\n",
    "    pen = 0.0\n",
    "    if omega <= 0: pen += (1 - 1e-6 - omega)**2\n",
    "    if alpha < 0:  pen += (0 - alpha)**2\n",
    "    if beta_ < 0:  pen += (0 - beta_)**2\n",
    "    if a <= 0:     pen += (1 - 1e-6 - a)**2\n",
    "    if b <= 0:     pen += (1 - 1e-6 - b)**2\n",
    "    if alpha + beta_ >= 1 - 5e-3:\n",
    "        pen += (alpha + beta_ - (1 - 5e-3))**2 * 1e2\n",
    "\n",
    "    s2 = _reconstruct_sigma2(y, omega, alpha, beta_)\n",
    "    sig = np.sqrt(np.maximum(s2, 1e-12))\n",
    "    mu_w, sd_w = beta_mean_std(a, b)\n",
    "    sd_w = max(sd_w, 1e-8)\n",
    "\n",
    "    z = y / sig\n",
    "    w = mu_w + sd_w * z\n",
    "\n",
    "    dist_left  = np.maximum(0.0, 0.0 - w)\n",
    "    dist_right = np.maximum(0.0, w - 1.0)\n",
    "    pen += np.sum(dist_left**2 + dist_right**2) * 1e2\n",
    "\n",
    "    eps = 1e-12\n",
    "    w_clip = np.clip(w, eps, 1 - eps)\n",
    "\n",
    "    ll_terms = (\n",
    "        (a - 1.0) * np.log(w_clip)\n",
    "        + (b - 1.0) * np.log1p(-w_clip)\n",
    "        - betaln(a, b)\n",
    "        + np.log(sd_w)\n",
    "        - np.log(sig)\n",
    "    )\n",
    "    nll = -float(np.sum(ll_terms)) + penalty_scale * pen\n",
    "    return nll\n",
    "\n",
    "def numerical_hessian(f, x, eps=2e-5):\n",
    "    x = np.asarray(x, float)\n",
    "    k = x.size\n",
    "    H = np.zeros((k, k), float)\n",
    "    for i in range(k):\n",
    "        for j in range(i, k):\n",
    "            ei = np.zeros_like(x); ei[i] = eps\n",
    "            ej = np.zeros_like(x); ej[j] = eps\n",
    "            fpp = f(x + ei + ej)\n",
    "            fpm = f(x + ei - ej)\n",
    "            fmp = f(x - ei + ej)\n",
    "            fmm = f(x - ei - ej)\n",
    "            H_ij = (fpp - fpm - fmp + fmm) / (4.0 * eps * eps)\n",
    "            H[i, j] = H_ij; H[j, i] = H_ij\n",
    "    return H\n",
    "\n",
    "def beta_se_three_from_hessian(y, theta5):\n",
    "    th = np.asarray(theta5, float)\n",
    "    def nll(th_): return beta_mle_negloglik(th_, y, penalty_scale=1e6)\n",
    "    H = numerical_hessian(nll, th, eps=2e-5)\n",
    "    H = 0.5*(H + H.T) + 1e-8*np.eye(H.shape[0])\n",
    "    try:\n",
    "        cov = np.linalg.pinv(H)\n",
    "        se5 = np.sqrt(np.clip(np.diag(cov), 0, np.inf))\n",
    "    except LinAlgError:\n",
    "        se5 = np.full(th.shape[0], np.nan)\n",
    "    return se5[:3]  # omega, alpha, beta\n",
    "\n",
    "# arch fits (QMLE / t)\n",
    "def arch_fit_params_and_se(y, dist='normal'):\n",
    "    \"\"\"\n",
    "    Return (params[omega, alpha, beta], SEs[omega, alpha, beta]) using robust covariance.\n",
    "    \"\"\"\n",
    "    model = arch_model(np.asarray(y, float), mean='zero', vol='GARCH', p=1, q=1, dist=dist)\n",
    "    res = model.fit(disp='off', show_warning=False, cov_type='robust')\n",
    "    params = np.array([res.params['omega'], res.params['alpha[1]'], res.params['beta[1]']], float)\n",
    "    ses = (res.std_err.reindex(['omega','alpha[1]','beta[1]']).astype(float).to_numpy())\n",
    "    return params, ses\n",
    "\n",
    "# Coverage computation\n",
    "def _safe_num(x):\n",
    "    try: return float(x)\n",
    "    except Exception: return np.nan\n",
    "\n",
    "def wald_cover(hat, se, true, z=1.96):\n",
    "    if not (np.isfinite(hat) and np.isfinite(se) and np.isfinite(true)): return np.nan\n",
    "    lo, hi = hat - z*se, hat + z*se\n",
    "    return float(lo <= true <= hi)\n",
    "def joint_indicator(covers):\n",
    "    c = np.asarray(covers, float)\n",
    "    if np.any(~np.isfinite(c)):\n",
    "        return np.nan\n",
    "    return float(np.all(c == 1.0))\n",
    "\n",
    "def compute_coverage(all_results, alpha=0.05):\n",
    "    z = norm.ppf(1 - alpha/2.0)\n",
    "    rows = []\n",
    "    for rec in all_results:\n",
    "        case, itype, iparam, rep = rec.get('case'), rec.get('innov_type'), rec.get('innov_param'), rec.get('rep')\n",
    "        y = rec.get('y_series')\n",
    "        if y is None: continue\n",
    "        y = np.asarray(y, float)\n",
    "\n",
    "        true_vec = np.array([_safe_num(rec.get('omega_true')),\n",
    "                             _safe_num(rec.get('alpha_true')),\n",
    "                             _safe_num(rec.get('beta_true'))], float)\n",
    "\n",
    "        # Beta-MLE: params from record; SE from Hessian\n",
    "        theta5 = [_safe_num(rec.get('omega_beta')),\n",
    "                  _safe_num(rec.get('alpha_beta')),\n",
    "                  _safe_num(rec.get('beta_beta')),\n",
    "                  _safe_num(rec.get('a_beta')),\n",
    "                  _safe_num(rec.get('b_beta'))]\n",
    "        if np.all(np.isfinite(theta5)):\n",
    "            hat_beta = np.array(theta5[:3], float)\n",
    "            se_beta  = beta_se_three_from_hessian(y, theta5)\n",
    "            covs = [wald_cover(hat_beta[i], se_beta[i], true_vec[i], z) for i in range(3)]\n",
    "            ci_lens = [2*z*se_beta[i] if np.isfinite(se_beta[i]) else np.nan for i in range(3)]\n",
    "            rows.append({\n",
    "                'case': case, 'innov_type': itype, 'innov_param': iparam, 'rep': rep,\n",
    "                'estimator': 'Beta-MLE',\n",
    "                'cover_omega': covs[0], 'cover_alpha': covs[1], 'cover_beta': covs[2],\n",
    "                'cover_joint': joint_indicator(covs),\n",
    "                'ci_len_omega': ci_lens[0], 'ci_len_alpha': ci_lens[1], 'ci_len_beta': ci_lens[2]\n",
    "            })\n",
    "\n",
    "        # QMLE (Gaussian)\n",
    "        try:\n",
    "            hat_q, se_q = arch_fit_params_and_se(y, dist='normal')\n",
    "            covs = [wald_cover(hat_q[i], se_q[i], true_vec[i], z) for i in range(3)]\n",
    "            ci_lens = [2*z*se_q[i] if np.isfinite(se_q[i]) else np.nan for i in range(3)]\n",
    "            rows.append({\n",
    "                'case': case, 'innov_type': itype, 'innov_param': iparam, 'rep': rep,\n",
    "                'estimator': 'Gaussian-QMLE',\n",
    "                'cover_omega': covs[0], 'cover_alpha': covs[1], 'cover_beta': covs[2],\n",
    "                'cover_joint': joint_indicator(covs),\n",
    "                'ci_len_omega': ci_lens[0], 'ci_len_alpha': ci_lens[1], 'ci_len_beta': ci_lens[2]\n",
    "            })\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # t-MLE\n",
    "        try:\n",
    "            hat_t, se_t = arch_fit_params_and_se(y, dist='t')\n",
    "            covs = [wald_cover(hat_t[i], se_t[i], true_vec[i], z) for i in range(3)]\n",
    "            ci_lens = [2*z*se_t[i] if np.isfinite(se_t[i]) else np.nan for i in range(3)]\n",
    "            rows.append({\n",
    "                'case': case, 'innov_type': itype, 'innov_param': iparam, 'rep': rep,\n",
    "                'estimator': 't-MLE',\n",
    "                'cover_omega': covs[0], 'cover_alpha': covs[1], 'cover_beta': covs[2],\n",
    "                'cover_joint': joint_indicator(covs),\n",
    "                'ci_len_omega': ci_lens[0], 'ci_len_alpha': ci_lens[1], 'ci_len_beta': ci_lens[2]\n",
    "            })\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    cover_long = pd.DataFrame(rows)\n",
    "\n",
    "    if cover_long.empty:\n",
    "        cols = ['case','innov_type','innov_param','estimator',\n",
    "                'cover_omega','cover_alpha','cover_beta','cover_joint',\n",
    "                'avg_ci_len_omega','avg_ci_len_alpha','avg_ci_len_beta']\n",
    "        cover_panel = pd.DataFrame(columns=cols)\n",
    "    else:\n",
    "        cover_panel = (cover_long\n",
    "            .groupby(['case','innov_type','innov_param','estimator'], dropna=False)\n",
    "            .agg(cover_omega=('cover_omega','mean'),\n",
    "                 cover_alpha=('cover_alpha','mean'),\n",
    "                 cover_beta =('cover_beta','mean'),\n",
    "                 cover_joint=('cover_joint','mean'),\n",
    "                 avg_ci_len_omega=('ci_len_omega','mean'),\n",
    "                 avg_ci_len_alpha=('ci_len_alpha','mean'),\n",
    "                 avg_ci_len_beta =('ci_len_beta','mean'))\n",
    "            .reset_index())\n",
    "\n",
    "    return cover_long, cover_panel\n",
    "\n",
    "cover_long, cover_panel = compute_coverage(all_results, alpha=0.05)\n",
    "\n",
    "#print(\"Coverage (mean over reps) by setting × estimator — first rows:\")\n",
    "#print(cover_panel)\n",
    "\n",
    "# joint coverage\n",
    "pivot_joint = (cover_panel\n",
    "    .pivot(index=['case','innov_type','innov_param'],\n",
    "           columns='estimator',\n",
    "           values='cover_joint')\n",
    "    .sort_index().round(4))\n",
    "#print(\"\\nPivot — Joint 95% coverage (ω,α,β simultaneously):\")\n",
    "#print(pivot_joint)\n",
    "\n",
    "# Coverage for each parameter\n",
    "pivot_cov_omega = cover_panel.pivot(index=['case','innov_type','innov_param'],\n",
    "                                    columns='estimator', values='cover_omega').sort_index().round(4)\n",
    "pivot_cov_alpha = cover_panel.pivot(index=['case','innov_type','innov_param'],\n",
    "                                    columns='estimator', values='cover_alpha').sort_index().round(4)\n",
    "pivot_cov_beta  = cover_panel.pivot(index=['case','innov_type','innov_param'],\n",
    "                                    columns='estimator', values='cover_beta').sort_index().round(4)\n",
    "\n",
    "#print(\"\\nPivot — 95% coverage of ω:\")\n",
    "#print(pivot_cov_omega)\n",
    "#print(\"\\nPivot — 95% coverage of α:\")\n",
    "#print(pivot_cov_alpha)\n",
    "#print(\"\\nPivot — 95% coverage of β:\")\n",
    "#print(pivot_cov_beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)      \n",
    "pd.set_option('display.max_columns', None)    \n",
    "pd.set_option('display.width', None)          \n",
    "pd.set_option('display.max_colwidth', None) \n",
    "print(\"Coverage (mean over reps) by setting × estimator — first rows:\")\n",
    "print(cover_panel.round(4))\n",
    "# joint coverage\n",
    "pivot_joint = (cover_panel\n",
    "    .pivot(index=['case','innov_type','innov_param'],\n",
    "           columns='estimator',\n",
    "           values='cover_joint')\n",
    "    .sort_index().round(4))\n",
    "print(\"\\nPivot — Joint 95% coverage (ω,α,β simultaneously):\")\n",
    "print(pivot_joint)\n",
    "\n",
    "\n",
    "# Coverage for each parameter\n",
    "pivot_cov_omega = cover_panel.pivot(index=['case','innov_type','innov_param'],\n",
    "                                    columns='estimator', values='cover_omega').sort_index().round(4)\n",
    "pivot_cov_alpha = cover_panel.pivot(index=['case','innov_type','innov_param'],\n",
    "                                    columns='estimator', values='cover_alpha').sort_index().round(4)\n",
    "pivot_cov_beta  = cover_panel.pivot(index=['case','innov_type','innov_param'],\n",
    "                                    columns='estimator', values='cover_beta').sort_index().round(4)\n",
    "\n",
    "print(\"\\nPivot — 95% coverage of ω:\")\n",
    "print(pivot_cov_omega)\n",
    "print(\"\\nPivot — 95% coverage of α:\")\n",
    "print(pivot_cov_alpha)\n",
    "print(\"\\nPivot — 95% coverage of β:\")\n",
    "print(pivot_cov_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Forecasting from all_results (schema-matched version)\n",
    "# ============================================================\n",
    "# Works with rows shaped like your screenshot:\n",
    "# {\n",
    "#   'case','innov_type','innov_param','rep',\n",
    "#   'omega_true','alpha_true','beta_true',\n",
    "#   'a_true','b_true','df_true',\n",
    "#   'omega_beta','alpha_beta','beta_beta','a_beta','b_beta',\n",
    "#   'omega_t','alpha_t','beta_t','df_t',\n",
    "#   'omega_qmle','alpha_qmle','beta_qmle',\n",
    "#   'y_series', 'sigma2_true'\n",
    "# }\n",
    "#\n",
    "# Produces per-row, per-estimator multi-step variance forecasts and\n",
    "# optional uncertainty paths. Robust to missing estimators in a row.\n",
    "\n",
    "import math\n",
    "from typing import Dict, Any, Tuple, List, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "def _is_finite(*vals) -> bool:\n",
    "    arr = np.asarray(vals, dtype=float)\n",
    "    return np.all(np.isfinite(arr))\n",
    "\n",
    "def _safe_last(arr: np.ndarray) -> float:\n",
    "    if arr is None or len(arr) == 0:\n",
    "        raise ValueError(\"Empty array encountered where a last element is required.\")\n",
    "    return float(arr[-1])\n",
    "\n",
    "# -----------------------------\n",
    "# 1. GARCH core\n",
    "# -----------------------------\n",
    "\n",
    "def one_step_ahead_sigma2(y_t: float, sigma2_t: float, omega: float, alpha: float, beta: float) -> float:\n",
    "    # σ²_{t+1|t} = ω + α y_t² + β σ_t²\n",
    "    return float(omega + alpha * (y_t ** 2) + beta * sigma2_t)\n",
    "def admissible_garch(omega, alpha, beta_):\n",
    "    return (np.isfinite([omega,alpha,beta_]).all() and\n",
    "            omega > 0 and alpha >= 0 and beta_ >= 0 and alpha + beta_ < 1 - 1e-6)\n",
    "\n",
    "def garch_hstep_from_sigma2_1(sigma2_t1: float, omega: float, alpha: float, beta_: float, h: int) -> float:\n",
    "    # Closed-form σ²_{t+h|t} given σ²_{t+1|t} (handles IGARCH limit).\n",
    "    if h == 1:\n",
    "        return sigma2_t1\n",
    "    kappa = alpha + beta_\n",
    "    if not np.isclose(kappa, 1.0):\n",
    "        return float(omega/(1.0-kappa) * (1.0 - kappa**(h-1)) + (kappa**(h-1))*sigma2_t1)\n",
    "    else:\n",
    "        return float(sigma2_t1 + omega*(h-1))\n",
    "\n",
    "def compute_conditional_variances(y: np.ndarray, omega: float, alpha: float, beta_: float, sigma2_0: Optional[float] = None) -> np.ndarray:\n",
    "    # Filtered σ²_t along the sample.\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    T = len(y)\n",
    "    if T == 0:\n",
    "        raise ValueError(\"y is empty.\")\n",
    "    kappa = alpha + beta_\n",
    "    if sigma2_0 is None:\n",
    "        if 0 <= kappa < 1 and omega > 0:\n",
    "            sigma2_0 = omega / (1.0 - kappa)\n",
    "        else:\n",
    "            v = float(np.var(y))\n",
    "            sigma2_0 = v if v > 0 else 1.0\n",
    "    sigma2 = np.empty(T, dtype=float)\n",
    "    sigma2[0] = float(sigma2_0)\n",
    "    for t in range(1, T):\n",
    "        sigma2[t] = omega + alpha * (y[t-1]**2) + beta_ * sigma2[t-1]\n",
    "    return sigma2\n",
    "\n",
    "def variance_forecast_path(y: np.ndarray, sigma2: np.ndarray, omega: float, alpha: float, beta_: float, h_max: int) -> np.ndarray:\n",
    "    # σ²_{t+h|t}, h=1..h_max, using last (y_T, σ²_T).\n",
    "    y_t = float(y[-1]); sigma2_t = float(sigma2[-1])\n",
    "    sigma2_t1 = one_step_ahead_sigma2(y_t, sigma2_t, omega, alpha, beta_)\n",
    "    out = np.empty(h_max, dtype=float)\n",
    "    out[0] = sigma2_t1\n",
    "    for h in range(2, h_max+1):\n",
    "        out[h-1] = garch_hstep_from_sigma2_1(sigma2_t1, omega, alpha, beta_, h)\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Innovation samplers (std)\n",
    "# -----------------------------\n",
    "\n",
    "def sample_std_beta(a: float, b: float, size: Tuple[int, int]) -> np.ndarray:\n",
    "    raw = np.random.beta(a, b, size=size)  # in [0,1]\n",
    "    mu = a / (a + b)\n",
    "    var = (a*b) / ((a+b)**2 * (a+b+1.0))\n",
    "    std = math.sqrt(var) if var > 0 else 1.0\n",
    "    return (raw - mu) / std\n",
    "\n",
    "def sample_std_student_t(nu: float, size: Tuple[int, int]) -> np.ndarray:\n",
    "    eps = np.random.standard_t(df=nu, size=size)\n",
    "    scale = math.sqrt((nu-2.0)/nu) if nu > 2 else 1.0\n",
    "    return eps * scale\n",
    "\n",
    "def sample_std_normal(size: Tuple[int, int]) -> np.ndarray:\n",
    "    return np.random.normal(size=size)\n",
    "\n",
    "def simulate_future_paths(omega: float,\n",
    "                          alpha: float,\n",
    "                          beta_: float,\n",
    "                          h_max: int,\n",
    "                          sigma2_start: float,\n",
    "                          dist: str,\n",
    "                          innov_params: Dict[str, float],\n",
    "                          n_paths: int = 0) -> Optional[np.ndarray]:\n",
    "    # Simulate n_paths of future returns.\n",
    "    if n_paths <= 0:\n",
    "        return None\n",
    "    size = (n_paths, h_max)\n",
    "    if dist == 'beta':\n",
    "        eps = sample_std_beta(float(innov_params['a']), float(innov_params['b']), size)\n",
    "    elif dist == 't':\n",
    "        eps = sample_std_student_t(float(innov_params['df']), size)\n",
    "    elif dist == 'normal':\n",
    "        eps = sample_std_normal(size)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dist '{dist}'.\")\n",
    "    paths = np.empty((n_paths, h_max), dtype=float)\n",
    "    sigma2_f = np.full(n_paths, float(sigma2_start), dtype=float)\n",
    "    for h in range(h_max):\n",
    "        y_f = np.sqrt(np.maximum(sigma2_f, 1e-12)) * eps[:, h]\n",
    "        paths[:, h] = y_f\n",
    "        if h < h_max-1:\n",
    "            sigma2_f = omega + alpha * (y_f**2) + beta_ * sigma2_f\n",
    "    return paths\n",
    "\n",
    "@dataclass\n",
    "class EstimatorPack:\n",
    "    name: str                  # 'beta_mle', 't_mle', 'qmle'\n",
    "    omega: float\n",
    "    alpha: float\n",
    "    beta_: float\n",
    "    innov: str                 # 'beta', 't', 'normal'\n",
    "    innov_params: Dict[str, float]\n",
    "\n",
    "def _extract_beta_mle(row: Dict[str, Any]) -> Optional[EstimatorPack]:\n",
    "    keys = ['omega_beta','alpha_beta','beta_beta','a_beta','b_beta']\n",
    "    if not all(k in row for k in keys): return None\n",
    "    omega, alpha, beta_, a, b = (row[k] for k in keys)\n",
    "    if not _is_finite(omega, alpha, beta_, a, b): return None\n",
    "    return EstimatorPack('beta_mle', float(omega), float(alpha), float(beta_), 'beta',\n",
    "                         {'a': float(a), 'b': float(b)})\n",
    "\n",
    "def _extract_t_mle(row: Dict[str, Any]) -> Optional[EstimatorPack]:\n",
    "    keys = ['omega_t','alpha_t','beta_t','df_t']\n",
    "    if not all(k in row for k in keys): return None\n",
    "    omega, alpha, beta_, df = (row[k] for k in keys)\n",
    "    if not _is_finite(omega, alpha, beta_, df): return None\n",
    "    return EstimatorPack('t_mle', float(omega), float(alpha), float(beta_), 't',\n",
    "                         {'df': float(df)})\n",
    "\n",
    "def _extract_qmle(row: Dict[str, Any]) -> Optional[EstimatorPack]:\n",
    "    keys = ['omega_qmle','alpha_qmle','beta_qmle']\n",
    "    if not all(k in row for k in keys): return None\n",
    "    omega, alpha, beta_ = (row[k] for k in keys)\n",
    "    if not _is_finite(omega, alpha, beta_): return None\n",
    "    return EstimatorPack('qmle', float(omega), float(alpha), float(beta_), 'normal', {})\n",
    "\n",
    "def extract_estimators(row: Dict[str, Any]) -> List[EstimatorPack]:\n",
    "    packs = []\n",
    "    for fn in (_extract_beta_mle, _extract_t_mle, _extract_qmle):\n",
    "        pack = fn(row)\n",
    "        if pack is not None:\n",
    "            packs.append(pack)\n",
    "    return packs\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Metrics (optional)\n",
    "# -----------------------------\n",
    "\n",
    "def compute_forecast_metrics(true_sigma2_tail: np.ndarray, forecasts: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "    # Per-horizon MSE/MAE/QLIKE against provided true variances.\n",
    "    H = len(forecasts)\n",
    "    K = min(H, len(true_sigma2_tail))\n",
    "    mse = np.full(H, np.nan); mae = np.full(H, np.nan); qlk = np.full(H, np.nan)\n",
    "    for h in range(K):\n",
    "        rv = float(true_sigma2_tail[h]); f = float(forecasts[h])\n",
    "        mse[h] = (rv - f)**2\n",
    "        mae[h] = abs(rv - f)\n",
    "        ratio = rv / max(f, 1e-12)\n",
    "        qlk[h] = ratio - math.log(max(ratio, 1e-300)) - 1.0\n",
    "    return {'MSE': mse, 'MAE': mae, 'QLIKE': qlk}\n",
    "\n",
    "# Oracle (true) forecast\n",
    "def oracle_forecast_from_row(row, h_max: int):\n",
    "    # Returns: forecast vector (len=h_max), kappa_true\n",
    "    y = np.asarray(row['y_series'], float)\n",
    "    sigma2_true = np.asarray(row['sigma2_true'], float)\n",
    "    omega = float(row['omega_true']); alpha = float(row['alpha_true']); beta_ = float(row['beta_true'])\n",
    "\n",
    "    # 1-step\n",
    "    sigma2_t1 = one_step_ahead_sigma2(y[-1], sigma2_true[-1], omega, alpha, beta_)\n",
    "    fcst = np.empty(h_max, float)\n",
    "    fcst[0] = sigma2_t1\n",
    "    for h in range(2, h_max+1):\n",
    "        fcst[h-1] = garch_hstep_from_sigma2_1(sigma2_t1, omega, alpha, beta_, h)\n",
    "    return fcst, (alpha + beta_)\n",
    "\n",
    "def compute_forecast_metrics_vs_oracle(row, forecasts: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "    oracle, _ = oracle_forecast_from_row(row, len(forecasts))\n",
    "    return compute_forecast_metrics(np.asarray(oracle, float), np.asarray(forecasts, float))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Per-row forecasting\n",
    "# -----------------------------\n",
    "\n",
    "def forecast_for_row(row: Dict[str, Any],\n",
    "                     h_max: int = 20,\n",
    "                     n_paths: int = 0,\n",
    "                     compute_metrics: bool = True,\n",
    "                     metrics_window: int = 200) -> List[Dict[str, Any]]:\n",
    "    # Produce variance forecasts for every estimator present in a row.\n",
    "    if 'y_series' not in row:\n",
    "        raise ValueError(\"Row missing 'y_series'.\")\n",
    "    y = np.asarray(row['y_series'], dtype=float)\n",
    "    if y.ndim != 1 or len(y) < 3:\n",
    "        raise ValueError(\"'y_series' must be 1-D with length >= 3.\")\n",
    "    sigma2_true = row.get('sigma2_true', None)\n",
    "    if sigma2_true is not None:\n",
    "        sigma2_true = np.asarray(sigma2_true, dtype=float)\n",
    "\n",
    "    packs = extract_estimators(row)\n",
    "    results = []\n",
    "\n",
    "    ident = {\n",
    "        'case': row.get('case', None),\n",
    "        'innov_type': row.get('innov_type', None),\n",
    "        'innov_param': row.get('innov_param', None),\n",
    "        'rep': row.get('rep', None),\n",
    "    }\n",
    "\n",
    "    for pack in packs:\n",
    "        if not admissible_garch(pack.omega, pack.alpha, pack.beta_):\n",
    "            continue\n",
    "        if pack.innov == 't' and float(pack.innov_params['df']) <= 2.1:\n",
    "            continue\n",
    "        # Rebuild filtered σ²_t from (y, theta_hat)\n",
    "        sigma2_series = compute_conditional_variances(y, pack.omega, pack.alpha, pack.beta_)\n",
    "\n",
    "        # Multi-step forecasts\n",
    "        forecasts = variance_forecast_path(y, sigma2_series, pack.omega, pack.alpha, pack.beta_, h_max=h_max)\n",
    "\n",
    "        # Optional return-path simulation for uncertainty\n",
    "        sigma2_last = _safe_last(sigma2_series)\n",
    "        sigma2_next = one_step_ahead_sigma2(y[-1], sigma2_last, pack.omega, pack.alpha, pack.beta_)\n",
    "        paths = simulate_future_paths(\n",
    "            pack.omega, pack.alpha, pack.beta_, h_max,\n",
    "            sigma2_start=sigma2_next,\n",
    "            dist=pack.innov, innov_params=pack.innov_params, n_paths=n_paths\n",
    "        )\n",
    "\n",
    "        out = {\n",
    "            **ident,\n",
    "            'estimator': pack.name,\n",
    "            'innov_for_sim': pack.innov,\n",
    "            'innov_params': pack.innov_params,\n",
    "            'omega': pack.omega, 'alpha': pack.alpha, 'beta': pack.beta_,\n",
    "            'kappa': pack.alpha + pack.beta_,\n",
    "            'sigma2_last': sigma2_last,\n",
    "            'sigma2_forecast': forecasts,\n",
    "            'paths': paths\n",
    "        }\n",
    "\n",
    "        if compute_metrics:\n",
    "            if sigma2_true is not None and len(sigma2_true) >= metrics_window:\n",
    "                true_tail = np.asarray(sigma2_true[-metrics_window:], dtype=float)\n",
    "                out['metrics'] = compute_forecast_metrics_vs_oracle(row, forecasts)\n",
    "            else:\n",
    "                out['metrics'] = None\n",
    "\n",
    "        results.append(out)\n",
    "\n",
    "    return results\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Batch driver over all_results\n",
    "# -----------------------------\n",
    "\n",
    "def run_forecasts_from_all_results(all_results: List[Dict[str, Any]],\n",
    "                                   h_max: int = 20,\n",
    "                                   n_paths: int = 0,\n",
    "                                   compute_metrics: bool = True,\n",
    "                                   metrics_window: int = 200,\n",
    "                                   verbose: bool = True) -> List[Dict[str, Any]]:\n",
    "    all_out: List[Dict[str, Any]] = []\n",
    "    for i, row in enumerate(all_results):\n",
    "        try:\n",
    "            row_out = forecast_for_row(row, h_max, n_paths, compute_metrics, metrics_window)\n",
    "            all_out.extend(row_out)\n",
    "            if verbose:\n",
    "                id_msg = f\"case={row.get('case')}, innov={row.get('innov_type')} {row.get('innov_param')}, rep={row.get('rep')}\"\n",
    "                ests = \", \".join(o['estimator'] for o in row_out)\n",
    "                # print(f\"[{i+1}/{len(all_results)}] {id_msg} → estimators: {ests}\")\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"[{i+1}/{len(all_results)}] Skipped due to error: {e}\")\n",
    "    return all_out\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Plot\n",
    "# -----------------------------\n",
    "\n",
    "def select_results(results: List[Dict[str, Any]],\n",
    "                   case=None, innov_type=None, innov_param=None, rep=None, estimator=None) -> List[Dict[str, Any]]:\n",
    "    sel = []\n",
    "    for r in results:\n",
    "        if case is not None and r.get('case') != case: \n",
    "            continue\n",
    "        if innov_type is not None and r.get('innov_type') != innov_type:\n",
    "            continue\n",
    "        if innov_param is not None and r.get('innov_param') != innov_param:\n",
    "            continue\n",
    "        if rep is not None and r.get('rep') != rep:\n",
    "            continue\n",
    "        if estimator is not None and r.get('estimator') != estimator:\n",
    "            continue\n",
    "        sel.append(r)\n",
    "    return sel\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Example usage\n",
    "# -----------------------------\n",
    "# H = 20\n",
    "#forecast_results = run_forecasts_from_all_results(all_results, h_max=H, n_paths=0,\n",
    "                                                 #compute_metrics=True, metrics_window=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UC and independence test\n",
    "from math import sqrt, log, isclose\n",
    "from typing import Dict, Optional, Tuple\n",
    "from scipy.stats import beta as beta_rv, t as t_rv, norm\n",
    "\n",
    "# ---------- helpers: innovation quantiles (standardized to mean 0, var 1) ----------\n",
    "\n",
    "def std_beta_quantile(a: float, b: float, alpha: float) -> float:\n",
    "    \"\"\"Quantile of standardized Beta(a,b).\"\"\"\n",
    "    q_raw = beta_rv.ppf(alpha, a, b)  # in [0,1]\n",
    "    mu = a / (a + b)\n",
    "    var = (a * b) / ((a + b) ** 2 * (a + b + 1.0))\n",
    "    sd = sqrt(var) if var > 0 else 1.0\n",
    "    return (q_raw - mu) / sd\n",
    "\n",
    "def std_t_quantile(df: float, alpha: float) -> float:\n",
    "    \"\"\"Quantile of standardized Student-t(df) with unit variance.\"\"\"\n",
    "    q_raw = t_rv.ppf(alpha, df)\n",
    "    scale = sqrt((df - 2.0) / df) if df > 2 else 1.0\n",
    "    return q_raw * scale\n",
    "\n",
    "def std_norm_quantile(alpha: float) -> float:\n",
    "    return norm.ppf(alpha)\n",
    "\n",
    "def std_innov_ppf(dist: str, params: Dict[str, float], alpha: float) -> float:\n",
    "    d = dist.lower()\n",
    "    if d == 'beta':\n",
    "        return std_beta_quantile(float(params['a']), float(params['b']), alpha)\n",
    "    elif d == 't':\n",
    "        return std_t_quantile(float(params['df']), alpha)\n",
    "    elif d == 'normal':\n",
    "        return std_norm_quantile(alpha)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown innovation '{dist}'.\")\n",
    "\n",
    "# ---------- UC and Independence tests ----------\n",
    "\n",
    "def christoffersen_counts(hits: np.ndarray) -> Tuple[int, int, int, int]:\n",
    "    \"\"\"Return n00, n01, n10, n11 for a 0/1 array of hits.\"\"\"\n",
    "    v = hits.astype(int)\n",
    "    n00 = np.sum((v[:-1] == 0) & (v[1:] == 0))\n",
    "    n01 = np.sum((v[:-1] == 0) & (v[1:] == 1))\n",
    "    n10 = np.sum((v[:-1] == 1) & (v[1:] == 0))\n",
    "    n11 = np.sum((v[:-1] == 1) & (v[1:] == 1))\n",
    "    return int(n00), int(n01), int(n10), int(n11)\n",
    "\n",
    "def lr_uc(hits: np.ndarray, alpha: float) -> Tuple[float, float, int, int]:\n",
    "    \"\"\"Christoffersen UC LR statistic and components.\"\"\"\n",
    "    K = len(hits)\n",
    "    S1 = int(np.sum(hits))\n",
    "    S0 = K - S1\n",
    "    p_hat = S1 / K if K > 0 else np.nan\n",
    "    # constrained/unconstrained log-likelihoods\n",
    "    logL_R = S0 * np.log(max(1 - alpha, 1e-300)) + S1 * np.log(max(alpha, 1e-300))\n",
    "    logL_U = S0 * np.log(max(1 - p_hat, 1e-300)) + S1 * np.log(max(p_hat, 1e-300))\n",
    "    LR = -2.0 * (logL_R - logL_U)\n",
    "    return LR, p_hat, S0, S1  # asymptotic χ²₁\n",
    "def lr_ind(hits: np.ndarray) -> tuple[float, dict]:\n",
    "    \"\"\"LR for independence (~ χ²_1) + counts/MLEs.\"\"\"\n",
    "    v = hits.astype(int)\n",
    "    n00 = int(np.sum((v[:-1]==0)&(v[1:]==0)))\n",
    "    n01 = int(np.sum((v[:-1]==0)&(v[1:]==1)))\n",
    "    n10 = int(np.sum((v[:-1]==1)&(v[1:]==0)))\n",
    "    n11 = int(np.sum((v[:-1]==1)&(v[1:]==1)))\n",
    "\n",
    "    p01 = n01 / (n00 + n01) if (n00+n01)>0 else 0.0\n",
    "    p11 = n11 / (n10 + n11) if (n10+n11)>0 else 0.0\n",
    "    S0  = n00 + n10\n",
    "    S1  = n01 + n11\n",
    "    p   = (S1 / (S0 + S1)) if (S0+S1)>0 else 0.0\n",
    "\n",
    "    def slog(x): return np.log(max(x, 1e-300))\n",
    "    logL_U = n00*slog(1-p01) + n01*slog(p01) + n10*slog(1-p11) + n11*slog(p11)\n",
    "    logL_R = S0*slog(1-p)    + S1*slog(p)\n",
    "    LR = -2.0*(logL_R - logL_U)   # ~ χ²(1)\n",
    "    return LR, {'p01_hat':p01,'p11_hat':p11,'p_hat':p,'n00':n00,'n01':n01,'n10':n10,'n11':n11}\n",
    "def lr_cc(hits: np.ndarray, alpha: float) -> tuple[float, dict]:\n",
    "    \"\"\"Conditional Coverage LR (χ² with 2 df) = UC + IND.\"\"\"\n",
    "    LR_uc, p_hat, S0, S1 = lr_uc(hits, alpha)\n",
    "    LR_ind, ind_info = lr_ind(hits)\n",
    "    LR_cc = LR_uc + LR_ind\n",
    "    return LR_cc, {\n",
    "        'LR_UC': LR_uc, 'LR_IND': LR_ind, 'p_hat': p_hat, 'S0': S0, 'S1': S1, **ind_info\n",
    "    }\n",
    "\n",
    "# ---------- Blockwise h-step VaR backtest ----------\n",
    "def var_backtest_blockwise(\n",
    "    y: np.ndarray,\n",
    "    omega: float, alpha: float, beta_: float,\n",
    "    innov: str, innov_params: Dict[str, float],\n",
    "    h: int, W: int, alpha_q: float\n",
    ") -> Dict[str, object]:\n",
    "    y = np.asarray(y, float); T = len(y) # Non-overlapping h-step-ahead VaR backtest\n",
    "    if not (1 <= h and 0 < W < T - h):\n",
    "        raise ValueError(\"Require 1<=h and 0<W<T-h.\")\n",
    "    # filter σ²_t along the sample\n",
    "    sigma2 = compute_conditional_variances(y, omega, alpha, beta_)\n",
    "    z_alpha = std_innov_ppf(innov, innov_params, alpha_q) # quantile of standardized innovations\n",
    "    # build hit sequence at non-overlapping blocks\n",
    "    tks = []\n",
    "    tk = W\n",
    "    while tk + h < T:       \n",
    "        tks.append(tk)\n",
    "        tk += h\n",
    "    hits = []\n",
    "    var_forecasts = []\n",
    "    for tk in tks:\n",
    "        # 1-step and then h-step from tk\n",
    "        sigma2_t1 = one_step_ahead_sigma2(y[tk], sigma2[tk], omega, alpha, beta_)\n",
    "        sigma2_th = garch_hstep_from_sigma2_1(sigma2_t1, omega, alpha, beta_, h)\n",
    "        var_alpha = np.sqrt(max(sigma2_th, 0.0)) * z_alpha\n",
    "        r_realized = y[tk + h]\n",
    "        hits.append(1 if r_realized < var_alpha else 0)\n",
    "        var_forecasts.append(var_alpha)\n",
    "\n",
    "    hits = np.asarray(hits, int)\n",
    "    K = len(hits); S1 = int(hits.sum()); S0 = K - S1\n",
    "    # tests\n",
    "    LR_uc, p_hat, _, _ = lr_uc(hits, alpha_q)\n",
    "    LR_ind, counts = lr_ind(hits)\n",
    "    LR_cc  = LR_uc + LR_ind\n",
    "\n",
    "    return {\n",
    "        'h': h, 'W': W, 'alpha': alpha_q,\n",
    "        'K': K, 'S0': S0, 'S1': S1, 'p_hat': p_hat,\n",
    "        'hits': hits, 'VaR': np.asarray(var_forecasts),\n",
    "        'LR_UC': LR_uc,          # ~ χ²(1)\n",
    "        'LR_IND': LR_ind,        # ~ χ²(1)\n",
    "        'LR_CC': LR_cc,          # ~ χ²(2)\n",
    "        'counts': counts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Batch forecast + metrics + VaR diagnostics over all_results ===== (only record several h, used to see exact numerical comparison)\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def _metrics_mean(m):\n",
    "    \"\"\"Return mean over finite entries of a 1-D metric vector.\"\"\"\n",
    "    v = np.asarray(m, dtype=float)\n",
    "    v = v[np.isfinite(v)]\n",
    "    return float(np.mean(v)) if v.size else np.nan\n",
    "\n",
    "def summarize_forecasts_and_var(\n",
    "    all_results,\n",
    "    h_max: int = 20,\n",
    "    h_list=(1, 5, 10),\n",
    "    W: int | None = None,\n",
    "    alpha_q: float = 0.01,\n",
    "    return_per_h_arrays: bool = False,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    For every row in all_results and every estimator present:\n",
    "      - make multi-step variance forecasts up to h_max\n",
    "      - compute MAE/MSE/QLIKE vs oracle (true-parameter) forecast at T\n",
    "      - for each h in h_list, run h-step, non-overlapping VaR backtest\n",
    "    Returns (df_raw, df_summary).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for row in all_results:\n",
    "        y = np.asarray(row['y_series'], float)\n",
    "        T = len(y)\n",
    "        if T < 3:\n",
    "            continue\n",
    "\n",
    "        # oracle h-step forecast from last origin using true params\n",
    "        fcst_true, kappa_true = oracle_forecast_from_row(row, h_max)\n",
    "\n",
    "        # choose W if not provided (use half-sample, rounded up)\n",
    "        W_eff = W if W is not None else int(np.ceil(0.3 * T))\n",
    "        W_eff = max(1, min(W_eff, T - max(h_list) - 1))\n",
    "\n",
    "        # which estimators are available in this row?\n",
    "        packs = extract_estimators(row)  # beta_mle / t_mle / qmle\n",
    "\n",
    "        for pack in packs:\n",
    "            # filtered sigma2 along sample & multi-step forecasts\n",
    "            sigma2_series = compute_conditional_variances(\n",
    "                y, pack.omega, pack.alpha, pack.beta_\n",
    "            )\n",
    "            fcst_hat = variance_forecast_path(\n",
    "                y, sigma2_series, pack.omega, pack.alpha, pack.beta_, h_max=h_max\n",
    "            )\n",
    "\n",
    "            # loss metrics per horizon (vs oracle)\n",
    "            metrics = compute_forecast_metrics(fcst_true, fcst_hat)\n",
    "            mae_vec, mse_vec, qlk_vec = metrics['MAE'], metrics['MSE'], metrics['QLIKE']\n",
    "            mae_mean = _metrics_mean(mae_vec)\n",
    "            mse_mean = _metrics_mean(mse_vec)\n",
    "            qlk_mean = _metrics_mean(qlk_vec)\n",
    "\n",
    "            # VaR diagnostics for each requested h\n",
    "            for h in h_list:\n",
    "                diag = var_backtest_blockwise(\n",
    "                    y=y,\n",
    "                    omega=pack.omega, alpha=pack.alpha, beta_=pack.beta_,\n",
    "                    innov=pack.innov, innov_params=pack.innov_params,\n",
    "                    h=h, W=W_eff, alpha_q=alpha_q\n",
    "                )\n",
    "\n",
    "                base = {\n",
    "                    'case': row.get('case'),\n",
    "                    'dgp_innov_type': row.get('innov_type'),\n",
    "                    'dgp_innov_param': row.get('innov_param'),\n",
    "                    'rep': row.get('rep'),\n",
    "                    'estimator': pack.name,            # 'beta_mle' | 't_mle' | 'qmle'\n",
    "                    'omega_hat': pack.omega, 'alpha_hat': pack.alpha, 'beta_hat': pack.beta_,\n",
    "                    'kappa_hat': pack.alpha + pack.beta_,\n",
    "                    'kappa_true': kappa_true,\n",
    "                    'h_max': h_max,\n",
    "                    'mae_mean': mae_mean,\n",
    "                    'mse_mean': mse_mean,\n",
    "                    'qlike_mean': qlk_mean,\n",
    "                    'alpha': diag['alpha'],\n",
    "                    'h_var': diag['h'],\n",
    "                    'W': diag['W'],\n",
    "                    'K_blocks': diag['K'],\n",
    "                    'S0': diag['S0'], 'S1': diag['S1'],\n",
    "                    'p_hat': diag['p_hat'],\n",
    "                    'LR_UC': diag['LR_UC'],            # ~ χ²(1)\n",
    "                    'LR_IND': diag['LR_IND'],          # ~ χ²(1) \n",
    "                    'n00': diag['counts']['n00'],\n",
    "                    'n01': diag['counts']['n01'],\n",
    "                    'n10': diag['counts']['n10'],\n",
    "                    'n11': diag['counts']['n11'],\n",
    "                }\n",
    "                if return_per_h_arrays:\n",
    "                    base['MAE_h'] = mae_vec.copy()\n",
    "                    base['MSE_h'] = mse_vec.copy()\n",
    "                    base['QLIKE_h'] = qlk_vec.copy()\n",
    "                    base['VaR_hits'] = diag['hits'].copy()\n",
    "                    base['VaR_path'] = diag['VaR'].copy()\n",
    "\n",
    "                rows.append(base)\n",
    "\n",
    "    df_raw = pd.DataFrame(rows)\n",
    "\n",
    "    # Summary by design cell (means across replications/rows)\n",
    "    group_cols = [\n",
    "        'case', 'dgp_innov_type', 'dgp_innov_param',\n",
    "        'estimator', 'h_var', 'alpha'\n",
    "    ]\n",
    "    mean_cols = ['mae_mean', 'mse_mean', 'qlike_mean', 'p_hat', 'LR_UC', 'LR_IND']\n",
    "    df_summary = (df_raw\n",
    "                  .groupby(group_cols, dropna=False)[mean_cols]\n",
    "                  .mean()\n",
    "                  .reset_index())\n",
    "\n",
    "    return df_raw, df_summary\n",
    "\n",
    "def add_pvalues_and_rejections(df_raw: pd.DataFrame, test_alpha: float = 0.05) -> pd.DataFrame:\n",
    "    df = df_raw.copy()\n",
    "    # Ensure correct names\n",
    "    assert 'LR_UC' in df.columns and 'LR_IND' in df.columns\n",
    "\n",
    "    df['pval_UC']  = chi2.sf(df['LR_UC'],  df=1)\n",
    "    df['pval_IND'] = chi2.sf(df['LR_IND'], df=1)\n",
    "\n",
    "    df['rej_UC']   = (df['pval_UC']  < test_alpha).astype(int)\n",
    "    df['rej_IND']  = (df['pval_IND'] < test_alpha).astype(int)\n",
    "    return df\n",
    "\n",
    "def summarize_by_design_with_mcse(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    group_cols = ['case','dgp_innov_type','dgp_innov_param','estimator','h_var','alpha']\n",
    "\n",
    "    def mcse_mean(x):\n",
    "        x = np.asarray(x, float); x = x[np.isfinite(x)]\n",
    "        n = x.size\n",
    "        return float(np.nanstd(x, ddof=1)/np.sqrt(n)) if n>1 else np.nan\n",
    "\n",
    "    def binom_mcse(x):\n",
    "        x = np.asarray(x, float); x = x[np.isfinite(x)]\n",
    "        n = x.size\n",
    "        if n == 0: return np.nan\n",
    "        p = float(np.nanmean(x))\n",
    "        return float(np.sqrt(p*(1-p)/n))\n",
    "\n",
    "    grp = df.groupby(group_cols, dropna=False)\n",
    "    out = grp.agg(\n",
    "        mae_mean   = ('mae_mean','mean'),\n",
    "        mae_mcse   = ('mae_mean', mcse_mean),\n",
    "        mse_mean   = ('mse_mean','mean'),\n",
    "        mse_mcse   = ('mse_mean', mcse_mean),\n",
    "        qlike_mean = ('qlike_mean','mean'),\n",
    "        qlike_mcse = ('qlike_mean', mcse_mean),\n",
    "        p_hat_mean = ('p_hat','mean'),\n",
    "        p_hat_mcse = ('p_hat', mcse_mean),\n",
    "\n",
    "        UC_rate    = ('rej_UC','mean'),\n",
    "        UC_mcse    = ('rej_UC', binom_mcse),\n",
    "        IND_rate   = ('rej_IND','mean'),\n",
    "        IND_mcse   = ('rej_IND', binom_mcse),\n",
    "    ).reset_index()\n",
    "    return out\n",
    "\n",
    "df_raw, _ = summarize_forecasts_and_var(\n",
    "    all_results,\n",
    "    h_max=20,\n",
    "    h_list=(1,5,10),\n",
    "    W=None,\n",
    "    alpha_q=0.01,\n",
    "    return_per_h_arrays=False # set True if want per-h vectors stored\n",
    ")\n",
    "df_raw2   = add_pvalues_and_rejections(df_raw, test_alpha=0.05)\n",
    "df_summary= summarize_by_design_with_mcse(df_raw2)  # Summarize across the 300 replications (per design cell)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record all metrics for all h, used for visualization\n",
    "from scipy.stats import chi2\n",
    "\n",
    "EPS = 1e-16\n",
    "\n",
    "def admissible_garch(omega, alpha, beta_):\n",
    "    return (np.isfinite([omega,alpha,beta_]).all()\n",
    "            and omega > 0 and alpha >= 0 and beta_ >= 0\n",
    "            and (alpha + beta_) < 1 - 1e-6)\n",
    "\n",
    "def ok_student_t(df):\n",
    "    return np.isfinite(df) and df > 2.1\n",
    "\n",
    "def implied_var_ok(omega, alpha, beta_, y):\n",
    "    \"\"\"Implied unconditional variance shouldn’t be absurd vs sample var.\"\"\"\n",
    "    kappa = alpha + beta_\n",
    "    if not (0 <= kappa < 1 - 1e-6):\n",
    "        return False\n",
    "    v_bar = omega / (1 - kappa)\n",
    "    sv = float(np.var(y))\n",
    "    if not np.isfinite(v_bar) or v_bar <= 0 or not np.isfinite(sv) or sv <= 0:\n",
    "        return False\n",
    "    ratio = v_bar / sv\n",
    "    return (1e-4 <= ratio <= 1e4)\n",
    "\n",
    "def pathological_forecast(fcst_true, fcst_hat):\n",
    "    \"\"\"Flag forecasts with absurd scale relative to oracle.\"\"\"\n",
    "    H = min(len(fcst_true), len(fcst_hat))\n",
    "    ft = np.asarray(fcst_true[:H], float)\n",
    "    fh = np.asarray(fcst_hat[:H], float)\n",
    "    if not (np.all(np.isfinite(ft)) and np.all(np.isfinite(fh))):\n",
    "        return True, \"non-finite forecast/oracle\"\n",
    "    med_t = float(np.nanmedian(ft)); med_h = float(np.nanmedian(fh))\n",
    "    if med_t <= 0 or med_h <= 0:\n",
    "        return True, \"non-positive median\"\n",
    "    ratio = med_h / med_t\n",
    "    if ratio < 1e-6 or ratio > 1e6:\n",
    "        return True, f\"scale mismatch ratio={ratio:.2e}\"\n",
    "    # near-zero path compared to oracle (your offender)\n",
    "    if np.all(fh < 1e-10 * med_t):\n",
    "        return True, \"near-zero forecast path\"\n",
    "    return False, \"\"\n",
    "\n",
    "def compute_forecast_metrics_safe(true_sigma2: np.ndarray, forecasts: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "    H = min(len(true_sigma2), len(forecasts))\n",
    "    out = {'MSE': np.full(H, np.nan), 'MAE': np.full(H, np.nan), 'QLIKE': np.full(H, np.nan)}\n",
    "    # scale-aware floor\n",
    "    med = np.nanmedian(true_sigma2[:H]); eps = EPS if not np.isfinite(med) or med <= 0 else 1e-12*med\n",
    "    for h in range(H):\n",
    "        rv = float(max(true_sigma2[h], eps))\n",
    "        f  = float(max(forecasts[h],   eps))\n",
    "        d  = rv - f\n",
    "        out['MSE'][h] = d*d\n",
    "        out['MAE'][h] = abs(d)\n",
    "        r = rv/f\n",
    "        out['QLIKE'][h] = r - math.log(max(r, 1e-300)) - 1.0\n",
    "    return out\n",
    "\n",
    "def _mcse_mean(x):\n",
    "    x = np.asarray(x, float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    n = x.size\n",
    "    return (np.nanstd(x, ddof=1)/np.sqrt(n)) if n>1 else np.nan\n",
    "\n",
    "def compute_all_h_metrics_and_var(\n",
    "    all_results,\n",
    "    h_max: int = 10,\n",
    "    metrics_h_list: list[int] | None = None,   \n",
    "    var_h_list: list[int] | None = None,      \n",
    "    W: int | None = None,\n",
    "    alpha_q: float = 0.05,\n",
    "    test_alpha: float = 0.05,\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if metrics_h_list is None:\n",
    "        metrics_h_list = list(range(1, h_max+1))\n",
    "    if var_h_list is None:\n",
    "        var_h_list = list(range(1, h_max+1))\n",
    "\n",
    "    rows_metrics = []\n",
    "    rows_var = []\n",
    "\n",
    "    for row in all_results:\n",
    "        y = np.asarray(row['y_series'], float)\n",
    "        T = len(y)\n",
    "        if T < 3:\n",
    "            continue\n",
    "\n",
    "        fcst_true, kappa_true = oracle_forecast_from_row(row, h_max)\n",
    "\n",
    "        packs = extract_estimators(row)  \n",
    "\n",
    "        W_eff = W if W is not None else int(np.ceil(0.3 * T))\n",
    "        W_eff = max(1, min(W_eff, T - max(max(metrics_h_list), max(var_h_list)) - 1))\n",
    "\n",
    "        for pack in packs:\n",
    "            if not admissible_garch(pack.omega, pack.alpha, pack.beta_):\n",
    "                continue\n",
    "            if pack.innov == 't' and not ok_student_t(float(pack.innov_params.get('df', np.inf))):\n",
    "                continue\n",
    "            if not implied_var_ok(pack.omega, pack.alpha, pack.beta_, y):\n",
    "                continue\n",
    "            sigma2_series = compute_conditional_variances(y, pack.omega, pack.alpha, pack.beta_)\n",
    "            sigma2_series = np.maximum(sigma2_series, EPS)\n",
    "            fcst_hat = variance_forecast_path(\n",
    "                y, sigma2_series, pack.omega, pack.alpha, pack.beta_, h_max=h_max\n",
    "            )\n",
    "            fcst_hat = np.maximum(fcst_hat, EPS)\n",
    "            is_bad, why = pathological_forecast(fcst_true, fcst_hat)\n",
    "            if is_bad:\n",
    "                continue\n",
    "\n",
    "            metrics = compute_forecast_metrics_safe(fcst_true, fcst_hat)\n",
    "            for h in metrics_h_list:\n",
    "                rows_metrics.append({\n",
    "                    'case': row.get('case'),\n",
    "                    'dgp_innov_type': row.get('innov_type'),\n",
    "                    'dgp_innov_param': row.get('innov_param'),\n",
    "                    'rep': row.get('rep'),\n",
    "                    'estimator': pack.name,\n",
    "                    'h_var': int(h),\n",
    "                    'metric': 'MAE',\n",
    "                    'value': float(metrics['MAE'][h-1])\n",
    "                })\n",
    "                rows_metrics.append({\n",
    "                    'case': row.get('case'),\n",
    "                    'dgp_innov_type': row.get('innov_type'),\n",
    "                    'dgp_innov_param': row.get('innov_param'),\n",
    "                    'rep': row.get('rep'),\n",
    "                    'estimator': pack.name,\n",
    "                    'h_var': int(h),\n",
    "                    'metric': 'MSE',\n",
    "                    'value': float(metrics['MSE'][h-1])\n",
    "                })\n",
    "                rows_metrics.append({\n",
    "                    'case': row.get('case'),\n",
    "                    'dgp_innov_type': row.get('innov_type'),\n",
    "                    'dgp_innov_param': row.get('innov_param'),\n",
    "                    'rep': row.get('rep'),\n",
    "                    'estimator': pack.name,\n",
    "                    'h_var': int(h),\n",
    "                    'metric': 'QLIKE',\n",
    "                    'value': float(metrics['QLIKE'][h-1])\n",
    "                })\n",
    "\n",
    "            for h in var_h_list:\n",
    "                diag = var_backtest_blockwise(\n",
    "                    y=y,\n",
    "                    omega=pack.omega, alpha=pack.alpha, beta_=pack.beta_,\n",
    "                    innov=pack.innov, innov_params=pack.innov_params,\n",
    "                    h=h, W=W_eff, alpha_q=alpha_q\n",
    "                )\n",
    "                pval_uc  = chi2.sf(diag['LR_UC'],  df=1)\n",
    "                pval_ind = chi2.sf(diag['LR_IND'], df=1)\n",
    "                pval_cc  = chi2.sf(diag['LR_CC'], df=2)\n",
    "\n",
    "                rows_var.append({\n",
    "                    'case': row.get('case'),\n",
    "                    'dgp_innov_type': row.get('innov_type'),\n",
    "                    'dgp_innov_param': row.get('innov_param'),\n",
    "                    'rep': row.get('rep'),\n",
    "                    'estimator': pack.name,\n",
    "                    'h_var': int(h),\n",
    "                    'alpha': diag['alpha'],\n",
    "                    'W': diag['W'],\n",
    "                    'K_blocks': diag['K'],\n",
    "                    'p_hat': diag['p_hat'],\n",
    "                    'LR_UC': diag['LR_UC'],\n",
    "                    'LR_IND': diag['LR_IND'],\n",
    "                    'pval_UC': pval_uc,\n",
    "                    'pval_IND': pval_ind,\n",
    "                    'rej_UC': int(pval_uc < test_alpha),\n",
    "                    'rej_IND': int(pval_ind < test_alpha),\n",
    "                    'LR_CC': diag['LR_CC'],\n",
    "                    'pval_CC': pval_cc,\n",
    "                    'rej_CC': int(pval_cc < test_alpha),\n",
    "                    'n00': diag['counts']['n00'],\n",
    "                    'n01': diag['counts']['n01'],\n",
    "                    'n10': diag['counts']['n10'],\n",
    "                    'n11': diag['counts']['n11'],\n",
    "                })\n",
    "    df_metrics_long = pd.DataFrame(rows_metrics).replace([np.inf, -np.inf], np.nan)\n",
    "    df_var_long     = pd.DataFrame(rows_var)\n",
    "    return df_metrics_long, df_var_long\n",
    "def _winsorize_mean(s, p_lo=1.0, p_hi=99.0):\n",
    "    x = s.to_numpy(float)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0: return np.nan\n",
    "    lo, hi = np.nanpercentile(x, [p_lo, p_hi])\n",
    "    x = np.clip(x, lo, hi)\n",
    "    return float(np.nanmean(x))\n",
    "def summarize_metrics_mcse(df_metrics_long: pd.DataFrame) -> pd.DataFrame:\n",
    "    group_cols = ['case','dgp_innov_type','dgp_innov_param','estimator','h_var','metric']\n",
    "    out = (df_metrics_long\n",
    "           .groupby(group_cols, dropna=False)\n",
    "           .agg(mean_val=('value',_winsorize_mean),\n",
    "                mcse_val=('value',_mcse_mean),\n",
    "                n_used=('value', lambda s: int(np.isfinite(s).sum())))\n",
    "           .reset_index())\n",
    "    return out\n",
    "\n",
    "def summarize_var_mcse(df_var_long: pd.DataFrame) -> pd.DataFrame:\n",
    "    group_cols = ['case','dgp_innov_type','dgp_innov_param','estimator','h_var','alpha']\n",
    "    def _binom_mcse(x):\n",
    "        x = np.asarray(x, float); x = x[np.isfinite(x)]\n",
    "        n = x.size\n",
    "        if n == 0: return np.nan\n",
    "        p = float(np.nanmean(x))\n",
    "        return float(np.sqrt(p*(1-p)/n))\n",
    "    out = (df_var_long\n",
    "           .groupby(group_cols, dropna=False)\n",
    "           .agg(p_hat_mean=('p_hat','mean'),\n",
    "                p_hat_mcse=('p_hat', _mcse_mean),\n",
    "                UC_rate=('rej_UC','mean'),   UC_mcse=('rej_UC', _binom_mcse),\n",
    "                IND_rate=('rej_IND','mean'), IND_mcse=('rej_IND', _binom_mcse),\n",
    "                CC_rate=('rej_CC','mean'),   CC_mcse=('rej_CC', _binom_mcse))\n",
    "                #K_median=('K_blocks','median'),\n",
    "                #S1_zero_frac=('S1', lambda s: float(np.mean(np.asarray(s)==0))))\n",
    "           .reset_index())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'beta_mle': 'Beta‑(Q)MLE',\n",
    "    't_mle': 't-(Q)MLE',\n",
    "    'qmle': 'Gaussian-(Q)MLE',\n",
    "}\n",
    "def plot_metric_for_dgp(\n",
    "    df_metrics_summary: pd.DataFrame,\n",
    "    case, dgp_innov_type, dgp_innov_param,\n",
    "    metric: str = 'MAE',\n",
    "    robust_ylim: bool = True,\n",
    "    title: str | None = None,\n",
    "    savepath: str | None = None\n",
    "):\n",
    "    sub = df_metrics_summary[\n",
    "        (df_metrics_summary['case']==case) &\n",
    "        (df_metrics_summary['dgp_innov_type']==dgp_innov_type) &\n",
    "        (df_metrics_summary['dgp_innov_param']==dgp_innov_param) &\n",
    "        (df_metrics_summary['metric'].str.upper()==metric.upper())\n",
    "    ].copy()\n",
    "\n",
    "    if sub.empty:\n",
    "        print(\"No data for the specified DGP/metric.\"); \n",
    "        return\n",
    "\n",
    "    estimators = ['beta_mle','t_mle','qmle']\n",
    "    colors = {'beta_mle':'tab:blue', 't_mle':'tab:green', 'qmle':'tab:orange'}  \n",
    "    linestyles = {\n",
    "    'beta_mle': '-',   \n",
    "    't_mle': '--',     \n",
    "    'qmle': '-'        \n",
    "}\n",
    "    markers = {\n",
    "    'beta_mle': 'o',\n",
    "    't_mle': 's',\n",
    "    'qmle': '^'\n",
    "}\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    for est in estimators:\n",
    "        d = sub[sub['estimator']==est].sort_values('h_var')\n",
    "        if d.empty: \n",
    "            continue\n",
    "        h = d['h_var'].to_numpy()\n",
    "        m = d['mean_val'].to_numpy()\n",
    "        s = d['mcse_val'].to_numpy()\n",
    "        label = label_map.get(est, est)\n",
    "        plt.plot(h, m, marker=markers[est], color=colors[est], label=label, linestyle=linestyles[est])             \n",
    "        plt.fill_between(h, m - s, m + s, alpha=0.2)       \n",
    "\n",
    "    plt.xlabel('Forecast horizon $h$', fontsize = 18)\n",
    "    plt.ylabel(metric.upper(), fontsize = 18)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12.5)\n",
    "    if title is None:\n",
    "        title = f\"Case:{case} — Innovation:{dgp_innov_type} {dgp_innov_param}\"\n",
    "    plt.title(title, fontsize = 18)\n",
    "    plt.legend(loc='best', fontsize = 15, frameon=False)\n",
    "\n",
    "    if robust_ylim:\n",
    "        yvals = sub['mean_val'].to_numpy()\n",
    "        if np.isfinite(yvals).any():\n",
    "            hi = np.nanpercentile(yvals, 99) * 1.25\n",
    "            lo = 0.0\n",
    "            if np.isfinite(hi) and hi > 0:\n",
    "                plt.ylim(lo, hi)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_long, df_var_long = compute_all_h_metrics_and_var(\n",
    "    all_results, h_max=10, metrics_h_list=None, var_h_list=None,\n",
    "    W=None, alpha_q=0.05, test_alpha=0.05\n",
    ")\n",
    "\n",
    "# Plot mean + MCSE for MAE, MSE, QLIKE\n",
    "dfM = summarize_metrics_mcse(df_metrics_long)\n",
    "dfV = summarize_var_mcse(df_var_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [\n",
    "    ('A', 'normal', 'None'),\n",
    "    ('B', 'normal', 'None'),\n",
    "    ('C', 'normal', 'None')\n",
    "]\n",
    "\n",
    "for case, innov_type, innov_param in cases:\n",
    "    fname = f\"plot_{case}_{innov_type}_{innov_param}.pdf\".replace(\" \", \"\")\n",
    "    plot_metric_for_dgp(dfM, case=case, dgp_innov_type=innov_type,\n",
    "                        dgp_innov_param=innov_param, metric='MAE',\n",
    "                        savepath=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_metric_for_dgp(dfM, case='A', dgp_innov_type='Beta',   dgp_innov_param='(2, 5)', metric='QLIKE')\n",
    "#plot_metric_for_dgp(dfM, case='A', dgp_innov_type='t',   dgp_innov_param='3', metric='QLIKE')\n",
    "#plot_metric_for_dgp(dfM, case='A', dgp_innov_type='normal',   dgp_innov_param='None', metric='QLIKE')\n",
    "#plot_metric_for_dgp(dfM, case='A', dgp_innov_type='t',   dgp_innov_param='8', metric='QLIKE')\n",
    "cases = [\n",
    "    ('A', 'Beta', '(2, 5)'),\n",
    "    ('A', 't', '3'),\n",
    "    ('A', 'normal', 'None'),\n",
    "    ('A', 't', '8')\n",
    "]\n",
    "\n",
    "for case, innov_type, innov_param in cases:\n",
    "    fname = f\"plot_{case}_{innov_type}_{innov_param}.pdf\".replace(\" \", \"\")\n",
    "    plot_metric_for_dgp(dfM, case=case, dgp_innov_type=innov_type,\n",
    "                        dgp_innov_param=innov_param, metric='QLIKE',\n",
    "                        savepath=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [\n",
    "    ('A', 'Beta', '(2, 5)'),\n",
    "    ('A', 'Beta', '(3, 3)'),\n",
    "    ('A', 'Beta', '(5, 2)'),\n",
    "    ('A', 't', '3'),\n",
    "    ('A', 't', '8'),\n",
    "    ('A', 't', '12'),\n",
    "    ('A', 'normal', 'None'),\n",
    "    ('B', 'Beta', '(2, 5)'),\n",
    "    ('B', 'Beta', '(3, 3)'),\n",
    "    ('B', 'Beta', '(5, 2)'),\n",
    "    ('B', 't', '3'),\n",
    "    ('B', 't', '8'),\n",
    "    ('B', 't', '12'),\n",
    "    ('B', 'normal', 'None'),\n",
    "    ('C', 'Beta', '(2, 5)'),\n",
    "    ('C', 'Beta', '(3, 3)'),\n",
    "    ('C', 'Beta', '(5, 2)'),\n",
    "    ('C', 't', '3'),\n",
    "    ('C', 't', '8'),\n",
    "    ('C', 't', '12'),\n",
    "    ('C', 'normal', 'None')\n",
    "    \n",
    "]\n",
    "\n",
    "for case, innov_type, innov_param in cases:\n",
    "    fname = f\"plot_{case}_{innov_type}_{innov_param}_MAE.pdf\".replace(\" \", \"\")\n",
    "    plot_metric_for_dgp(dfM, case=case, dgp_innov_type=innov_type,\n",
    "                        dgp_innov_param=innov_param, metric='MAE',\n",
    "                        savepath=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var_rejection_rates_for_dgp(\n",
    "    df_var_summary: pd.DataFrame,\n",
    "    case, dgp_innov_type, dgp_innov_param,\n",
    "    test: str = 'UC',                 # 'UC' or 'IND' or 'CC'\n",
    "    alpha_filter: float | None = None,\n",
    "    estimators: list[str] | None = None,\n",
    "    test_alpha_line: float | None = 0.05,  # rejection ratio baseline\n",
    "    use_crit: float = 1,              # 1 => ±1*SE; 1.96 => ~95%CI\n",
    "    robust_ylim: bool = True,\n",
    "    title: str | None = None,\n",
    "    colors: dict[str,str] | None = None,\n",
    "    markers: dict[str,str] | None = None,\n",
    "    linestyles: dict[str,str] | None = None,\n",
    "    figsize=(6,4),\n",
    "    savepath: str | None = None      \n",
    "):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    test = test.upper()\n",
    "    if test not in ('UC','IND', 'CC'):\n",
    "        raise ValueError(\"test must be 'UC' or 'IND'\")\n",
    "\n",
    "    rate_col = f'{test}_rate'\n",
    "    se_col   = f'{test}_mcse'\n",
    "\n",
    "    sub = df_var_summary[\n",
    "        (df_var_summary['case']==case) &\n",
    "        (df_var_summary['dgp_innov_type']==dgp_innov_type) &\n",
    "        (df_var_summary['dgp_innov_param']==dgp_innov_param)\n",
    "    ].copy()\n",
    "    if alpha_filter is not None:\n",
    "        sub = sub[np.isclose(sub['alpha'], alpha_filter)]\n",
    "\n",
    "    if sub.empty:\n",
    "        print(\"No data for specified DGP/test/alpha.\")\n",
    "        return\n",
    "\n",
    "    if estimators is None:\n",
    "        estimators = ['beta_mle','t_mle','qmle']\n",
    "    if colors is None:\n",
    "        colors = {'beta_mle':'tab:blue', 'qmle':'tab:orange','t_mle':'tab:green'}\n",
    "    if markers is None:\n",
    "        markers = {'beta_mle':'o', 't_mle':'s', 'qmle':'^'}\n",
    "    if linestyles is None:\n",
    "        linestyles = {'beta_mle':'-', 't_mle':'--', 'qmle':'-'}\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for est in estimators:\n",
    "        d = (sub[sub['estimator']==est].sort_values(['alpha','h_var']))\n",
    "        if d.empty:\n",
    "            continue\n",
    "        h  = d['h_var'].to_numpy()\n",
    "        r  = d[rate_col].to_numpy()\n",
    "        se = d[se_col].to_numpy()\n",
    "\n",
    "        plt.plot(h, r, label=f\"{est}\",\n",
    "                 color=colors.get(est), marker=markers.get(est),\n",
    "                 linestyle=linestyles.get(est))\n",
    "        if np.isfinite(se).any():\n",
    "            plt.fill_between(h, r - use_crit*se, r + use_crit*se,\n",
    "                             alpha=0.2, color=colors.get(est))\n",
    "\n",
    "    plt.xlabel('Forecast horizon $h$', fontsize = 18)\n",
    "    plt.ylabel(f'{test} rejection rate', fontsize = 18)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12.5)\n",
    "    if title is None:\n",
    "        a_text = (f\"α={alpha_filter}\" if alpha_filter is not None\n",
    "                  else f\"α∈{{{', '.join(map(str, sorted(sub['alpha'].unique())))}}}\")\n",
    "        title = f\"Case{case} - {dgp_innov_type} {dgp_innov_param} - {test} - VaR level α = {alpha_filter}\"\n",
    "    plt.title(title, fontsize = 18)\n",
    "    if test_alpha_line is not None:\n",
    "        plt.axhline(test_alpha_line, linestyle=':', linewidth=1.2, alpha=0.8)\n",
    "\n",
    "    if robust_ylim:\n",
    "        y = sub[rate_col].to_numpy()\n",
    "        if np.isfinite(y).any():\n",
    "            lo = max(0.0, np.nanmin(y) - 0.05)\n",
    "            hi = min(1.0, np.nanpercentile(y, 99) * 1.25 + 0.02)\n",
    "            plt.ylim(lo, hi)\n",
    "\n",
    "    plt.legend(loc='best', fontsize = 13, frameon=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case, innov_type, innov_param in cases:\n",
    "    fname = f\"plot_{case}_{innov_type}_{innov_param}_UC.pdf\".replace(\" \", \"\")\n",
    "    plot_var_rejection_rates_for_dgp(dfV, case=case, dgp_innov_type=innov_type,\n",
    "                        dgp_innov_param=innov_param, test='UC',alpha_filter=0.05,estimators=['beta_mle','t_mle','qmle'],test_alpha_line=0.05,     # baseline\n",
    "                        use_crit=1,             # ±1*SE, same as in the QLIKE plot\n",
    "                        savepath=fname)\n",
    "for case, innov_type, innov_param in cases:\n",
    "    fname = f\"plot_{case}_{innov_type}_{innov_param}_IND.pdf\".replace(\" \", \"\")\n",
    "    plot_var_rejection_rates_for_dgp(dfV, case=case, dgp_innov_type=innov_type,\n",
    "                        dgp_innov_param=innov_param, test='IND',alpha_filter=0.05,estimators=['beta_mle','t_mle','qmle'],test_alpha_line=0.05,     \n",
    "                        use_crit=1,            \n",
    "                        savepath=fname)\n",
    "for case, innov_type, innov_param in cases:\n",
    "    fname = f\"plot_{case}_{innov_type}_{innov_param}_CC.pdf\".replace(\" \", \"\")\n",
    "    plot_var_rejection_rates_for_dgp(dfV, case=case, dgp_innov_type=innov_type,\n",
    "                        dgp_innov_param=innov_param, test='CC',alpha_filter=0.05,estimators=['beta_mle','t_mle','qmle'],test_alpha_line=0.05,     \n",
    "                        use_crit=1,            \n",
    "                        savepath=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases2 = [\n",
    "    ('A', 'Beta', '(2, 5)'),\n",
    "    ('A', 't', '3'),\n",
    "    ('A', 't', '8'),\n",
    "    ('A', 'normal', 'None')\n",
    "]\n",
    "for case, innov_type, innov_param in cases2:\n",
    "    fname = f\"plot_{case}_{innov_type}_{innov_param}_CC.pdf\".replace(\" \", \"\")\n",
    "    plot_var_rejection_rates_for_dgp(dfV, case=case, dgp_innov_type=innov_type,\n",
    "                        dgp_innov_param=innov_param, test='CC',alpha_filter=0.05,estimators=['beta_mle','t_mle','qmle'],test_alpha_line=0.05,     \n",
    "                        use_crit=1,            \n",
    "                        savepath=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases2 = [\n",
    "    ('A', 'normal', 'None'),\n",
    "    ('B', 'normal', 'None'),\n",
    "    ('C', 'normal', 'None')\n",
    "]\n",
    "for case, innov_type, innov_param in cases2:\n",
    "    fname = f\"plot_{case}_{innov_type}_{innov_param}_UC.pdf\".replace(\" \", \"\")\n",
    "    plot_var_rejection_rates_for_dgp(dfV, case=case, dgp_innov_type=innov_type,\n",
    "                        dgp_innov_param=innov_param, test='UC',alpha_filter=0.05,estimators=['beta_mle','t_mle','qmle'],test_alpha_line=0.05,     \n",
    "                        use_crit=1,            \n",
    "                        savepath=fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_var_rejection_rates_for_dgp(\n",
    "    dfV,\n",
    "    case='A',\n",
    "    dgp_innov_type='t',\n",
    "    dgp_innov_param='12',\n",
    "    test='CC',\n",
    "    alpha_filter=0.05,      \n",
    "    estimators=['beta_mle','t_mle','qmle'],\n",
    "    test_alpha_line=0.05,     # baseline\n",
    "    use_crit=1             # ±1*SE, same as in the QLIKE plot\n",
    ")\n",
    "plot_var_rejection_rates_for_dgp(\n",
    "    dfV,\n",
    "    case='A',\n",
    "    dgp_innov_type='normal',\n",
    "    dgp_innov_param='None',\n",
    "    test='CC',\n",
    "    alpha_filter=0.05,\n",
    "    use_crit=1,            \n",
    "    test_alpha_line=0.05\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
